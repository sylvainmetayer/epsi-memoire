\subsection{Gestion de projet}

\epigraph{\frquote{Avoir 300 personnes dans une cuisine pour faire un œuf au plat ne permettra pas de servir le plat 300 fois plus vite}}{Analogie de la \frquote{Loi de Brooks\footnote{\url{https://fr.wikipedia.org/wiki/Loi_de_Brooks}}}}

\subsubsection{Partie financière}
L'automatisation d'un projet ne peut s'effectuer un en jour. De même que la citation ci-dessus a du sens, la migration d'un projet existant vers une automatisation totale ne peut s'effectuer en un jour, même en mobilisant de grands moyens. Il est donc nécessaire de préparer et planifier une conduite du changement qui permettra d'accompagner tous les acteurs du projet afin que la transition s'effectue dans les meilleures conditions possibles. Cela passe d'abord par une réflexion sur la conduite à adopter et les changements à apporter. 

Prenons pour exemple un projet fonctionnel depuis maintenant plusieurs mois. Le projet a déjà été livré (avec plus ou moins de difficulté) quelques fois en production. Comment convaincre que l'automatisation va apporter du bien à ce projet ? Qui est-il nécessaire de convaincre ?

Tout d'abord, il faut convaincre les personnes responsables financièrement du projet. En effet, il est possible d'avoir un projet automatisé de A à Z, si ce processus d'automatisation vient à coûter 3 fois le prix total vendu au client, aucun responsable ne vous donnera son accord. Il va également falloir convaincre les personnes responsables du projet (chef de projet, directeur de projet...) qu'il y a un intérêt à effectuer cela. En effet, sans garantie que ce processus pourra amener quelque chose de positif, peu laisseront une opportunité d'essayer d'automatiser un projet.

Il faut ainsi préparer son argumentaire, avec les bienfaits que cela pourra obtenir sur les \gls{KPI} et sur la vie du projet à moyen/long terme.

\begin{description}
	\setlength\itemsep{0em}
	\item [La durée de de déploiement] peut être réduite pour permettre de se concentrer sur d'autres problématiques. De plus, si les temps de déploiement sont réduits, cela signifie que les temps d'interruption de service pourront être réduit lors des livraisons.
	\item [Erreur de déploiement] Si les déploiements sont automatisés, les risques d'incidents lors des déploiements, souvent dû à des erreurs humaines, seront alors réduit.
	\item [Rentabilité financière] Prenons une tâche qui coûte \numprint{3000}€ à réaliser toutes les 3 semaines. Son coût est donc assez élevé. Le fait d'automatiser cette tâche permettra d'économiser de l'argent sur la durée. Si le fait d'automatiser cette tâche coûte par exemple, \numprint{10000}€, un gain sera perçu dès la 12\up{ème} semaine.\label{ref-rentabilite-finance}
	\item [Part de marché] Si les déploiements sont plus fiables et rapides, que la rentabilité financière du projet est également florissante alors il sera possible de concentrer les efforts sur des fonctionnalités à fortes valeurs ajoutées qui permettront ainsi de se démarquer de la concurrence et d'augmenter les parts de marché à moyen/long terme. C'est ce que les économistes appellent la compétitivité hors-prix.
	\item [\Gls{timetomarket}] Dans un environnement très concurrentiel, il est essentiel de pouvoir intervenir rapidement. Réduire la durée entre la naissance d'une idée/besoin et sa mise en production est important, sous peine de voir des concurrents prendre des parts de marché. L'automatisation peut alors permettre de déployer rapidement et avec confiance les développements réalisés.
	\item [Reprise d'activité] Il s'agit ici de démontrer que le produit parfait n'existe pas. Il arrivera que l'application soit hors ligne à cause d'un incident ou qu'une mise à jour entraine une interruption de service. En revanche, si l'on ne peut éviter l'incident à un moment donné, il est capital de pouvoir restaurer l'application rapidement. Disposer d'un \gls{PCA} ou d'un \gls{PRA} intégrant une automatisation de la reprise d'activité est un atout non négligeable qui permettra une reprise de l'activité au plus vite. On peut alors passer d'une interruption de plusieurs heures à une se comptant en minutes.\label{ref-pra}
\end{description}

\subsubsection{Organiser le flux de travail}
Il est également nécessaire de planifier au mieux les durées des travaux à accomplir afin d'éviter des dépassements dans les délais annoncés. Cela implique donc de réfléchir au temps nécessaire à investir et aux différents jalons qui valideront la bonne mise en place de l'automatisation. 

Pour pouvoir mettre en place une démarche d'automatisation sur un projet, il est nécessaire que ce dernier soit assez mature pour pouvoir s'y adapter. Ainsi, comme l'indique \citetitle{phoenixProject} \cite{phoenixProject}, avant de se lancer dans une démarche d'automatisation (\emph{ou plus globalement, pour pouvoir gérer correctement un projet}), la première étape est de savoir gérer le flux de travail.

Le flux de travail, ce sont les différentes tâches qui sont à réaliser sur le projet. Ces dernières sont souvent des stories (\emph{dans le cas d'une méthodologie agile}), définies conjointement avec le client et correspondent ainsi à ce qui a été défini dans le cahier des charges. L'inconvénient est que ce flux de travail est fragile. Il peut rapidement dériver et se retrouver perturbé, surchargeant ainsi les équipes. Le principal ennemi de flux de travail est le travail non prévu (\emph{unplanned work}). Ce sont toutes les petites tâches non prévues, qui prennent 10 à 15 minutes, qui ne sont suivies nulle part et qui mises bout à bout peuvent faire perdre plusieurs jours de travail et épuiser les équipes, qui ne voit jamais le travail diminuer.

Quelles sont donc les solutions pour gérer ce travail non prévu ? L'objectif est ici de faire en ce sorte que ce travail non prévu ne soit plus exécuté directement sans passer par une phase minimale de planification. Pour cela, il est possible de mettre en place des kanbans. Qu'est-ce qu'un Kanban ? Il s'agit d'une méthode de représentation des tâches qui permet de visualiser l'avancée du projet en temps réel (\emph{ou du moins, à chaque fois que le tableau est mis à jour}). On peut ainsi limiter le travail non prévu, en l'ajoutant à une catégorie dédiée, le \emph{backlog}, qui correspond à la pile de tâche à réaliser. Une fois ces tâches estimées, découpées et discutées avec le client, elles peuvent être considérées comme prêtes à être commencées. On parle alors de \emph{Définition Of Ready}. De même, pour déterminer qu'une tâche a été terminée par l'équipe de développement et donc prête à être livrée, on parle de \emph{Definition Of Done}, ce qui correspond à une liste de points, établi par l'équipe en interne. Ces points correspondent à des éléments à vérifier et à cocher pour indiquer si une tâche est vraiment terminée ou non. On peut y retrouver par exemple l'écriture de tests ou encore le fait qu'une autre personne ait relu le code, le fait que la documentation ait été mise à jour\ldots

On peut ensuite suivre l'évolution des tâches dans leur différentes étapes, du développement à leur livraison, en passant par les tests. Ainsi, le travail non prévu ne peut plus déranger un sprint en cours puisqu'il est possible de définir des limites, en disant par exemple que seules les tâches étant prêtes seront travaillées dans ce sprint et que les autres devront attendre le prochain sprint pour pouvoir être traitées. Néanmoins, il s'agit de faire attention à un point en mettant en place un kanban. En effet, si l'on met simplement en place un kanban et que l'on continue de traiter les tâches comme elles l'étaient précédemment, on s'expose au risque de voir le travail en cours, ou \emph{WIP\footnote{Work In Progress}} s'accumuler. Cela risque donc de ralentir les équipes voir de les démotiver. De plus, si tout le travail est en WIP, il n'y a aucune façon de savoir depuis combien de temps un tâche est débutée, ce qui fait que certaines tâches peuvent très bien rester en WIP pendant des jours voir des semaines. La solution à ce problème tient dans le fait de limiter le travail en cours. En effet, en limitant le travail en cours, on s'assure que les tâches ne resteront pas éternellement en attente. De plus, si le travail en cours est restreint, il sera de meilleur qualité, puisque moins dispersé et engendrera donc moins de bug !

\subsubsection{Livrer plus rapidement de la valeur métier}

L'un des objectifs de l'automatisation est également de faciliter le passage d'un système où l'on met plusieurs mois avant de livrer une grosse fonctionnalité à un autre où de multiples petites fonctionnalités sont livrées plus régulièrement. Attendre plusieurs mois pour livrer une fonctionnalité peut en effet avoir des effets indésirables.

\begin{itemize}
	\setlength\itemsep{0em}
	\item Dans une époque hyper-concurrentielle où l'on veut tout, toujours plus vite, certains besoins sont éphémères ou nécessitent un \gls{timetomarket} faible pour se démarquer de la concurrence. Si la fonctionnalité est livrée une fois le besoin passé, cette dernière n'a plus de sens. Cela vaut aussi si l'on vient à livrer un produit une fois que tous les concurrents sont déjà positionnés dessus. Il vaut mieux livrer petit à petit des parties du besoin pour pouvoir l'améliorer continuellement.
	\item Une fonctionnalité qui met longtemps à être livrée induira un stress au niveau des équipes, qui auront sur leurs épaules la responsabilité de livrer \emph{la fonctionnalité parfaite}, plutôt que livrer plusieurs petites fonctionnalités.
	\item Le risque d'échec est beaucoup plus important en livrant une fonctionnalité plutôt que plusieurs petites, surtout si cette dernière inclut des changements d'architecture (\emph{Structure de la base de données, ajout de nouveaux composants...})
	\item Plus on attend longtemps pour livrer une fonctionnalité, plus on prend le risque de se retrouver dans le cas d'un \emph{effet tunnel} ou la compréhension de ce qui était à faire s'est retrouvée au fur et à mesure du temps par être l'opposé de ce qui était demandé. Dans cette position, le client et le chef de projet communique souvent peu, l'équipe de développement travaille en général sans avertir de ses avancées,\ldots Seule la date limite permet de voir ce qui a été réalisé et il s'agit plus souvent d'un échec que d'une réussite.
\end{itemize}

Cette volonté de vouloir livrer plus petit mais plus régulièrement s'inscrit dans \emph{l'amélioration continue}. Au début, la fonctionnalité ne sera peut-être pas parfaite, mais elle sera continuellement améliorée jusqu'à correspondre au besoin voulu. On peut voir cela illustré sur la figure \ref{fig:devopsObjective} avec l'illustration de la collaboration entre les développeurs (qui apportent de la valeur ajoutée au client) et les administrateurs systèmes (qui mettent à disposition l'application au client). On constate tout de suite qu'il vaut mieux livrer plusieurs petites fonctionnalités (et donc avoir une forte collaboration entre les deux équipes) apportant chacune une valeur ajoutée certes plus faible plutôt que le premier schéma où si la livraison échoue, le client se retrouve sans application.

\newImage[H]{1}{devops-objective.jpg}{Mise en place de l'amélioration continue entre \emph{Dev} et \emph{Ops} - \url{https://itrevolution.com}}{devopsObjective}

Néanmoins, il convient de vérifier que ce système est intégré et accepté par l'équipe, sous peine de voir un rejet de cette méthodologie \devops{} et d'entrainer des conflits internes au sein des équipes. Cela peut être le cas avec certaines personnes réfractaires au changement, par exemple des développeurs âgés, proches de le retraite, qui n'ont peut-être pas envie de se former à nouveau et s'adapter à de nouvelles méthodes de travail et qui tenteront de garder leurs habitudes. Cela peut également provenir de personnalités avec un fort caractère qui pensent que leur méthode est plus efficace que les autres ou encore de bien d'autres cas. De manière générale, les personnes ne souhaitent pas sortir de leur zone de confort. Pour permettre ce changement, il va falloir exposer les différents avantages aux équipes et leur montrer les intérêts qu'ils ont à s'essayer à cette méthode pour peut-être finir par l'adopter de leur plein gré. 

Afin de faire intégrer ce système par une équipe, il faut tout d'abord trouver des personnes qui sont ouvertes au changement, des \glsplural{earlyadopter} qui ont envie de voir cette amélioration se mettre en place. Dans l'idéal, ces personnes seront également des personnes influentes vis-à-vis des autres afin de permettre une meilleure intégration du changement par le suite. Il faut ensuite convaincre une majorité de personne et les amener vers ce changement. L'idée est de construire une base plus importante de personnes souhaitant voir cette évolution se mettre en place afin de ne laisser que les personnes réfractaires au changement à gérer par la suite, quitte à les mettre devant le fait accompli une fois une majorité de personnes convaincues. On peut voir cette mise en place de la culture \devops{} détaillée dans \citetitle{devOpsHandbook} \cite[p.58-59]{devOpsHandbook}.

\subsubsection{Retours et apprentissage continu}

L'un des premiers avantages si l'on met en place une démarche d'automatisation est une meilleure communication entre les développeurs, également appelés \emph{Dev}, et les administrateurs systèmes, appelés \emph{Ops}. Si l'on met en place une démarche d'automatisation, un besoin de métrique va être nécessaire. Ces métriques, semblables aux \gls{KPI} précédemment détaillés, permettront de savoir par exemple le temps de déploiement de l'application, les derniers bugs remontés, les suivis de performance afin de déterminer si une requête \gls{SQL} est trop lente ou non\ldots{} Ces métriques, conjointement définies par les développeurs et les administrateurs systèmes vont permettre d'obtenir des retours rapides sur l'état de l'application et ainsi de pouvoir améliorer le produit plus facilement, en corrigeant les bugs au plus tôt. C'est la base de la \emph{Second Way}, ou deuxième étape, comme expliqué dans \citetitle{phoenixProject} \cite[p.405-410]{phoenixProject}.

Un autre point à prendre en compte lors d'une démarche d'automatisation est l'apprentissage continu. Comme nous l'avons vu dans la partie précédente, \etsy{} a mis en place un outil de post-mortem (p.\pageref{post-mortem}) qui permet de savoir les erreurs rencontrées dans le passé et de permettre qu'elles ne se reproduisent plus. Cette notion constitue la \emph{Third Way} mais ne se limite pas seulement aux erreurs rencontrées. Avec le temps obtenu par l'automatisation, il est ainsi possible de s'améliorer sur d'autres points : partager les connaissances de chacun pour faire progresser l'équipe et les personnes la constituant, documenter et améliorer l'intégration de nouvelles personnes dans les équipes ou les environnements de travail\ldots{} L'équipe sera alors plus performante et pourra ainsi délivrer de meilleurs produits.

\subsection{Environnement de développement}

L'environnement de développement est le premier environnement où sont développées les différentes fonctionnalités du projet. Ce cadre de travail doit pouvoir être installé rapidement afin de se concentrer sur le développement de fonctionnalités et non sur l'installation de l'environnement de travail.

\subsubsection{Arrivée sur le projet}

Plusieurs personnes sont potentiellement amenées à travailler sur le projet. Il est donc important de documenter l'installation et les pré-requis afin de pouvoir commencer à travailler. Il n'est malheureusement pas rare de voir des projets où la documentation du projet est faible, voir inexistante.

L'idéal pour un développeur qui vient d'arriver sur un projet serait de disposer d'un environnement prêt à l'emploi, qui puisse se lancer en quelques commandes (installation des dépendances et provisionnement de l'environnement). Des outils de conteneurisation tel que Docker\footnote{\url{https://www.docker.com/}} permettent ainsi d'avoir des environnements isolés et reproductibles quelque soit l'environnement du développeur. De plus, avec Docker, l'architecture du projet est représenté sous forme textuelle et donc intégrable dans le \gls{SCM}, ce qui permet de savoir les évolutions sur l'architecture du projet facilement. De plus, un projet qui peut s'installer rapidement signifie qu'un développeur peut être efficient plus rapidement sur son projet. Il peut ainsi apporter ses compétences sur de réelles problématiques plutôt qu'être bloqué pendant de longues heures à chercher comment installer ledit projet.

Afin de permettre un démarrage rapide, il est également commun de mettre des alias sur les commandes les plus utilisées lors des développements. Par exemple, si une commande permettant d'effacer le cache de l'application est longue à taper, on la raccourcira en quelque chose tel que \frquote{make clear} par exemple. Pour cela, plusieurs solutions sont disponibles : les scripts \gls{PHP} dans le cas d'un projet \gls{PHP} ou encore l'utilisation des Makefile, permettant de construire les logiciels et leur dépendances et d'y effectuer des tâches diverses, définies dans un fichier. Il est également possible d'écrire des scripts shell\footnote{L'interpréteur de commande disponible sous Linux, pas la compagnie pétrolière \emoji{😊}}, permettant d'effectuer des tâches plus complexes\footnote{Comme faire le café ? \emoji{😊} - \url{https://github.com/NARKOZ/hacker-scripts}}

De plus, il est souvent nécessaire d'avoir des configurations spécifiques sur les environnements de développements. En effet, dans un contexte de développement, on va vouloir obtenir les erreurs immédiatement, dans un terminal par exemple, alors que dans un environnement de production, ces dernières seront dans un fichier de log. De plus, on va pouvoir vouloir tracer le temps que prend chaque requête vers une base de données ou encore disposer d'outils permettant de mettre des points d'arrêts dans le code afin de pouvoir débugger lors des phases de développements. Il faut donc des moyens d'activer ses outils simplement. Cela peut passer par des scripts ou encore des images Docker dédiées au développement, basée sur celle de production. Le but est d'obtenir un environnement le plus proche possible de la production tout en ayant la possibilité d'ajouter des outils de développements additionnels.

\subsubsection{Build local}

Le build local correspond à la première boucle de retour du développeur. C'est dans cet environnement qu'il obtient des retours rapide, que cela soit sur ses tests unitaire, ses éventuelles fautes de frappe, erreur de syntaxe\ldots. L'objectif de ce build local est de détecter les erreurs au plus tôt, pour éviter qu'elles ne soient potentiellement oubliées et non détectées par les autres étapes du flux de travail et provoque un bug en production alors qu'il aurait pu être évité simplement. Plusieurs solutions peuvent alors être mises en place pour améliorer ce build local.

\paragraph{L'utilisation d'un IDE}

L'objectif de l'\gls{IDE} est de fournir un support de travail au développeur et de lui repérer de façons automatique des erreurs d'inattention. Il convient alors de se familiariser avec un \gls{IDE} afin de tirer le maximum de ce dernier. Parmi les fonctionnalités communes d'un bon \gls{IDE}, on retrouve :

\begin{itemize}
	\setlength\itemsep{-0.5em}
	\item Détection des erreurs de syntaxe
	\item Ajout automatique des imports dans un fichier
	\item Lancement automatique des tests unitaire à la sauvegarde/modification d'un fichier
	\item Auto-complétion automatique permettant de connaître le nom des méthodes et fonction à la saisie
	\item Indenter le code selon des conventions définies
	\item Affichage des erreurs simple à détecter (tel qu'un code non atteignable car après un retour de fonction par exemple)
\end{itemize}

Les \gls{IDE} disposent souvent de plugins qui permettent d'étendre leurs fonctionnalités pour améliorer le quotidien du développeur. Par exemple, certains plugins vont permettre de gérer l'affichage de l'état de la base de données, s'interfacer avec l'état des outils d'intégrations continue distants (via les \gls{API} de ces derniers) afin de savoir si les tests d'intégrations sont passés ou non\ldots

\paragraph{Les hooks du SCM} Git, \gls{SCM} utilisé de façon majoritaire dans les développements dispose d'un mécanisme permettant d'étendre ses fonctionnalités : les hooks. Ces hooks, tel que décrits dans la documentation (\citetitle{git-hook} \cite[chapitre 8.3]{git-hook}) permettent de lancer des scripts à certaines étapes, tel qu'avant un commit, avant de pousser le code sur le serveur, après réception des modifications du serveur\ldots{} Cela permet souvent de vérifier que les tests unitaires passent, qu'il n'y a pas d'erreur de syntaxe ou encore que le linter\footnote{analyse de code statique permettant de détecter les erreurs communes, et d'instaurer une syntaxe (règles d'espacement, nommage des variables\ldots) commune} ne génère pas d'erreur.

\paragraph{Le pair programming (programmation en binôme)}

Le pair programming consiste à développer à deux développeurs sur le même poste de travail. Bien qu'au premier abord, cela puisse sembler être une perte de temps et d'argent (puisqu'il n'y a finalement qu'une seule personne qui tape sur le clavier), cette méthode permet de détecter des erreurs plus tôt, puisqu'il y a 2 paires d'yeux qui peuvent relever les erreurs au lieu d'une seule. Souvent, il peut arriver un développeur seul d'être \frquote{la tête dans le guidon}, c'est-à-dire qu'il est tellement absorbé dans son code et peut donc oublier certains cas, certaines règles métiers\ldots{} Le fait de travailler en binôme permet ainsi de déceler ces erreurs plus tôt et d'assurer une meilleure qualité de code. Les deux développeurs échangent rapidement leurs rôles afin de travailler de façon efficace et de passer d'observateur à développeur. 

\subsection{L'importance des tests} \label{importance-test}

Les tests ont un rôle crucial dans une démarche d'automatisation. En effet, lorsque l'on automatise quelque chose, il est essentiel de s'assurer que le comportement de l'application est valide puisque l'on va par la suite déployer automatiquement cette application en production. Selon le \gls{CFTL}, il existe 4 types de tests et chacun dispose de quatre objectifs formant ainsi une matrice représentée dans le tableau \ref{tab:matrice-test}.

\begin{table}[H]
	\centering
	\begin{adjustbox}{width=0.95\textwidth,center=\textwidth} 
		\begin{tabular}{|l|l|l|l|l|}
			\hline
			\diagbox{type de test}{valide} & Fonctionnement unitaire & Règle métier & Développement & Interaction \\ \hline
			Test de composant     & X                       & X            & X              &             \\ \hline
			Test d'intégration    &                         & X            & X              & X           \\ \hline
			Test Système          &                         & X            &               & X           \\ \hline
			Test d'acceptation    &                         & X            &               &             \\ \hline
		\end{tabular}
	\end{adjustbox}
	\caption{Matrice de tests selon leur type et leur objectif}
	\label{tab:matrice-test}
\end{table}

\subsubsection{Le test de composant}\label{test-composant}

Son objectif est que le composant testé soit totalement isolé afin de se concentrer uniquement sur le \emph{fonctionnement unitaire} de ce dernier, sans dépendre d'autre composant. On peut alors tester tous les cas, du cas dit \frquote{général}, qui représente souvent 80\% des cas, jusqu'aux \frquote{cas limites}, cas apparaissant plus rarement mais pouvant entrainer un comportement non souhaité de l'application. Cela permet de vérifier que le code écrit par le développeur lors de la phase de \emph{développement} est bien valide. Ainsi, un test de composant peut valider des \emph{règles métier} et ainsi également correspondre à un test d'acceptation\footnote{détails sur les tests d'acceptation dans la sous partie \frquote{\nameref{test-acceptation}} (p. \pageref{test-acceptation})}.

Un exemple commun de test de composant est par exemple le test d'une méthode de calcul d'une calculette. On dispose d'une méthode \frquote{calculer} disposant de 3 paramètres, 2 \frquote{opérandes} numériques et un \frquote{opérateur}. Un cas général serait alors de tester que \frquote{3+2} retourne bien \frquote{5} et un cas limite serait de tester que \frquote{5/0} lève bien une exception, puisqu'il s'agit d'une opération illégale. Dans le cas de \gls{PHP}, un exemple de \gls{framework} de test unitaire est PHPUnit\footnote{\url{https://phpunit.de/}}. Le principal avantage de ce type de test est sa rapidité : ne nécessitant aucune interaction avec des composants externes (ou bien ces composants disposent d'un \gls{mock}), l'exécution des tests est très rapide.

\subsubsection{Le test d'intégration}

Une fois chaque composant testé unitairement, il convient de vérifier que ces composants sont capable d'\emph{interagir} entre eux. En effet, dans la sous-partie précédente, il était indiqué que les composants étaient isolés les uns des autres. Néanmoins, dans de nombreux cas, il est nécessaire que des composants interagissent entre eux. On va alors utiliser un \gls{mock} afin de simuler le comportement d'un composant, afin de tester l'autre.

Un exemple serait une \gls{API} qui communiquerait avec une base de données afin de retourner les résultats. Lorsque l'on teste l'\gls{API} unitairement, on ne souhaite pas dépendre de la base de données. On va donc simuler les réponses normalement fournies par la base de données et envoyer ces données à l'\gls{API} qui pourra alors être testée de façon isolée.

Cependant, si l'on teste toute notre application de cette façon, il est impossible d'attester le bon fonctionnement de nos composants entre eux. La version de la base de données pourrait en effet être incompatible avec le code actuellement utilisé par l'\gls{API}. Si aucun test d'intégration n'est effectué, la confiance dans l'application sera basée sur le \gls{mock} de la base de données et on risque alors de se retrouver dans le cas de la figure \ref{fig:no-integration-test}, avec des composants isolés fonctionnant très bien individuellement mais incapable de s'exécuter ensemble. Cela s'illustre avec la figure \ref{fig:no-integration-test}. Dans ce cas, les tiroirs s'ouvrent très bien individuellement mais lorsqu'ils sont assemblés, il n'est pas possible d'ouvrir les deux tiroirs en même temps, puisque le premier bloque l'ouverture du second.

\newImage{0.4}{no-integration-tests.png}{Exemple de tests unitaire sans tests d'intégration.}{no-integration-test}

Les tests d'intégration vont donc garantir que chaque composant, déployé dans l'environnement d'exécution de l'application, est capable de communiquer de façon correcte avec ses dépendances.

\subsubsection{Le test système}

Les tests systèmes permettent de tester le comportement de l'application sans forcément avoir connaissance du code. Cela permet ainsi de vérifier que l'application effectue bien ce qui est indiqué dans les spécifications demandées et que les différents composants interagissent bien entre eux. Ces tests sont également appelés \frquote{tests boite noire}. De plus, les tests systèmes permettent de vérifier que les composants interagissent correctement entre eux, au niveau global de l'application (\emph{au niveau système}) et non en mettant un composant dans l'application et en regardant son comportement avec les autres composants, comme c'est le cas avec le test d'intégration.

Ce sont également les tests qui sont les plus hauts niveaux, puisqu'ils s'exécutent avec toute l'application et ses dépendances / composants. On peut par exemple citer les tests End to End qui sont des tests systèmes qui permettent de tester le comportement d'une application de bout en bout en décrivant les actions réalisées sur cette dernière (cliquer sur un bouton, réduire la fenêtre) et les résultats attendus.

Le \gls{framework} \gls{angularjs} , par exemple, permet de réaliser des tests End to End avec Protractor\footnote{\url{https://www.protractortest.org/}}. Cela va ainsi émuler un navigateur dans lequel il va être possible de décrire les comportements utilisateurs. 

Un autre exemple de test système serait un test de charge, réalisé sur un environnement similaire à la production, durant lequel on ne va pas tester la conformité de l'application mais sa capacité à supporter un certain trafic. Dans le cas d'une application web, cela consiste à simuler des centaines ou milliers de connexions simultanées sur le site afin de vérifier sa capacité à répondre convenablement. Évidemment, tester ceci sur un environnement avec une configuration différente de la production n'a que peu de sens, puisque le serveur de test sera alors sous-dimensionné, sur-dimensionné ou disposera d'une gestion du cache différente par exemple mais dans tous les cas, les résultats seront faussés.

L'avantage de ces tests systèmes est qu'il s'agit des tests les plus complets, puisqu'ils permettent de tester le produit fini. L'inconvénient est qu'ils sont plus longs à exécuter.

\subsubsection{Le test d'acceptation}\label{test-acceptation}

Souvent réalisé par le client, il va consister, au travers d'une campagne de test généralement manuelle, à vérifier que les \emph{règles métiers} sont bien respectées. Le client peut néanmoins décider de déléguer ce test à une équipe qualité, ou à un prestataire externe.

Il est néanmoins possible que certains tests d'acceptation soient validés en amont, comme l'exemple de la calculatrice donnée dans la partie \frquote{\nameref{test-composant}} (p. \pageref{test-composant}) qui va valider la \emph{règle métier} (effectuer une opération) tout en validant le bon fonctionnement du code et ses cas limites.

\subsubsection{Les tests par mutation}\label{ref-mutation}

L'objectif des tests par mutation est de vérifier la pertinence des cas de tests. En effet, une couverture de 100\% de code via des tests ne garantit pas que 100\% du code soit réellement testé. Voici le déroulement des tests par mutation : 

\begin{enumerate}
	\setlength\itemsep{0em}
	\item On part d'une classe métier sur laquelle on souhaite vérifier la pertinence de nos tests.
	\item On détermine les opérations possibles à effectuer : changement de condition, changement d'opérateurs (< ; > ; <= ; >= ; != ; == ; \ldots), \ldots
	\item On génère alors des \frquote{mutants}\footnote{Évidemment, des outils existent afin de générer ces mutants automatiquement. En \gls{PHP}, \url{https://github.com/infection/infection} est utilisé pour générer et présenter les résultats de ces tests par mutation} qui vont correspondre à tous les changements possibles selon les critères définis à l'étape précédente. C'est une étape qui peut être très longue à générer selon le nombre de critères sélectionnés dans l'étape précédente. Une fois cela effectué, on va donc disposer de plusieurs classes \frquote{mutantes}.
	\item On lance alors notre test contre la classe métier originale, et on s'assure que les tests soient valides.
	\item On lance ensuite les tests sur chacune des classes \frquote{mutantes}.
\end{enumerate}

Logiquement, le code ayant changé, des erreurs dans les tests devraient alors apparaitre dans un ou plusieurs cas. Si tous les tests sont valides, cela veut dire que le test ignore un ou plusieurs comportements de la classe et qu'il faut revoir la pertinence des tests.

\subsubsection{Choisir les type de tests à prioriser}

Chaque application étant différente, tous les types de tests ne sont pas adaptés à toutes les applications. Il faut donc déterminer les tests à prioriser, selon le type de produit que l'on livre.

Ainsi, dans le cas d'une application métier complexe, telle que les banques, assurances ou les cas d'utilisations sont nombreux et nécessitent des algorithmes potentiellement compliqués, il peut être intéressant de concentrer ses efforts sur des tests d'acceptation via des tests unitaire pour valider les besoins métiers, du fait de leur criticité.

Si l'on vient à travailler avec des \gls{cms} ou que l'on interagit avec des services qui ne sont pas de notre ressort, il y a des risques non négligeables de se retrouver dans des cas où les mises à jour de ces services risquent d'entrainer des régressions. Il faut alors concentrer ses efforts sur les tests d'intégration pour s'assurer que le code développé puisse correctement s'exécuter avec les librairies tierces.

\subsection{Intégration, déploiement et livraison continue}

Une fois que les tests permettent de modifier le code de l'application avec confiance sans introduire de régression, on peut alors mettre en place une démarche d'automatisation. Cela va permettre à l'équipe de développement d'obtenir un retour rapide lors de chaque déploiement, avec un lancement automatisé des tests ainsi qu'un déploiement automatique de l'application sur un environnement de test interne par exemple.

L'un des objectifs de l'intégration et du déploiement continu est de banaliser le déploiement afin de réduire la peur des développeurs vis-à-vis de la mise en production. Plus le code est déployé souvent, plus les développeurs seront sereins quant à leur travail puisqu'ils pourront obtenir des retours rapide et être prévenus au plus vite lors d'incident afin de les corriger avant qu'il n'atteigne la production.

\subsubsection{Gestion de version, de branches et des opérations}

Il est tout d'abord essentiel de définir une stratégie de gestion de version et de branches du code, afin de s'assurer une bonne mise en place de l'automatisation. De plus, il est important de réfléchir aux actions qui devront être entrepris dans chaque cas. 

En effet, avec l'automatisation du processus d'intégration, de livraison et de déploiement, il est nécessaire d'adopter en amont des \emph{conventions} afin de couvrir les différents cas qui pourraient survenir. Les actions entreprises ne seront pas les mêmes pour couvrir une opération de qualimétrie du code que pour gérer le déploiement d'un \gls{hotfix}.

\paragraph{Gestion de branches}

La gestion de branches est importante à bien définir puisqu'elle va rythmer les flux de travail de développement des équipes. Il n'est donc pas envisageable de changer les habitudes de travail des équipes toutes les 3 semaines sous prétexte que ce flux de travail sera plus adapté avec les outils d'intégration ou de déploiement continu.

On peut alors définir des conventions de nommage des branches. Par exemple, on peut utiliser une branche \emph{master} qui représente l'état de la version de production et une autre branche \emph{develop} dite de développement sur laquelle les \emph{Dev} travaillent. Une branche de \gls{hotfix} peut être conventionnellement nommée \emph{hotfix\_NUMERO\_INCIDENT} par exemple pour gérer les incidents de production. Une fois ces conventions mises en place, il sera alors plus facile de déterminer différents comportements dans les outils d'intégration et de déploiement continu, tel que Jenkins à titre d'exemple.

\emph{Au niveau des branches, de nombreuses conventions existent, ci-dessous est présenté un exemple.}

Le feature branching, aussi connu sous le nom de \frquote{git flow} consiste à organiser son processus de développement sous forme de branche, en faisant correspondre à chaque fonctionnalité une branche. On conserve le principe de branche \emph{master} et \emph{develop} présentée dans le paragraphe précédent, mais à chaque fois que l'on souhaite développer une fonctionnalité, on crée une branche en se basant depuis \emph{develop}, ce qui permet de laisser les branches de développement et de production relativement saine. Une fois le développement de la fonctionnalité terminée, il suffit alors de \emph{merger}\footnote{fusionner le code original et le code développé sur la branche de fonctionnalité} les deux branches pour récupérer le travail.

\newImage{0.2}{feature-branching.png}{Illustration du feature branching - \url{https://www.atlassian.com}}{feature-branching}

Le feature flipping n'est pas à proprement parler un flux de travail puisqu'il peut très bien s'accorder sur un flux de travail tel que le feature branching ou sur une branche simple mais il est intéressant de le mentionner. Il consiste à envelopper chaque fonctionnalité avec un paramètre de configuration, de sorte à pouvoir activer et désactiver rapidement des fonctionnalités. Cela peut permettre de tester des nouvelles fonctionnalités progressivement vis-à-vis des utilisateurs ou d'effectuer du \gls{test-a-b} afin de déterminer quelle solution est la plus plébiscitée par les utilisateurs. 

Un exemple de feature flipping peut être le déploiement de la nouvelle interface de Gandi\footnote{\url{http://gandi.net/}} qui a progressivement proposé sa nouvelle interface\footnote{\url{https://news.gandi.net/fr/tag/gandiv5/}} à ses utilisateurs via un bouton leur permettant de tester la nouvelle interface, tout en leur autorisant un retour à l'ancienne s'ils le souhaitaient. 

\paragraph{Gestion de version}\label{gestion-de-version}

Une fois que l'on a déterminé la façon dont le code source sera organisé, il est nécessaire de déterminer la façon dont les versions du logiciel seront effectuées. En effet, il faut être en mesure de pouvoir dire quelle version est déployée sur quel environnement. Il est rare de disposer seulement d'une production, on dispose à minima pour un projet d'un environnement de recette et d'une pré-production, et souvent d'un contexte de staging pour pouvoir valider les modifications à différentes étapes et éviter de se retrouver avec un bug en production. Ainsi, il n'est pas rare d'avoir une version A en production, avec une version B en pré-production et une version C en recette client.

La version doit être immuable, c'est-à-dire qu'il ne doit pas être possible de déclarer deux fois la même version. Une fois déclarée, la version doit être taguée dans le \gls{SCM} afin d'en garder une trace et de la retrouver si besoin. Concernant le format de la version, il doit pouvoir être automatiquement incrémenté par les outils d'intégration et de déploiement continus. On recommande généralement d'utiliser un format standardisé, tel que le Semanting Versionning\footnote{\url{https://semver.org/}} dont le but est d'indiquer via le numéro de version les compatibilités entre version. Ainsi, une version 1.0.0 et une 2.0.0 peuvent entrainer des non-compatibilités ascendantes ou descendantes. Néanmoins, une 1.0.0 et une 1.1.0 indique l'ajout de fonctionnalités n'entrainant pas de non-compatibilités et la différence entre une 1.0.0 et une 1.0.1 indique l'ajout d'un correctif mineur.

\paragraph{Gestion des opérations}

Une fois la façon dont le code est géré par le \gls{SCM} et la façon dont on nomme nos versions, on peut se poser la question sur les différentes actions à effectuer. Suite à une modification du code, on va en effet vouloir effectuer des actions rapides pour pouvoir valider que ce dernier est fonctionnel (en lançant les tests unitaire par exemple) mais on ne va pas vouloir forcément produire immédiatement la qualimétrie du code, qui peut prendre du temps à être générée et donc faire attendre les équipes de développements qui attendent un retour rapide. De même, selon les clients, on va vouloir déployer automatiquement un projet s'il passe les tests d'intégration et les tests systèmes, mais certains projets anciens n'ayant pas forcément assez de tests ne peuvent peut-être pas se permettre un déploiement immédiat et il faudra alors demander une validation manuelle.

Les opérations sont à prévoir pour tous les cas pouvant intervenir, qu'il s'agisse de déploiement d'une nouvelle version, d'un \gls{hotfix} ou de la construction de dépendances internes étant réutilisés par d'autres applications. On peut consulter sur l'annexe \ref{annexe:release-naq} le diagramme des opérations pour le déploiement d'une nouvelle version d'un site de la \naq{} qui passera par 4 environnements, un de staging, suivi d'une recette effectuée par le client, puis d'une pré-production et enfin de l'environnement de production. On constate que le serveur d'intégration continu (ici Jenkins) est au cœur des opérations effectuées et sert de chef d'orchestre pour interagir avec les autres outils et environnements.

Une autre notion que l'on peut voir sur ce schéma est la notion de promotion d'artifact. Un artifact représente un fichier (dans ce cas, une archive contenant le site à déployer) stocké sur un \gls{artifactory}. Ce fichier va, au cours du \emph{pipeline}\footnote{Flux de travail}, être validé selon qu'il a ou non été correctement déployé sur un environnement donné. On va alors promouvoir ce fichier selon des statuts prédéfinis arbitrairement afin de situer l'évolution du fichier. Les statuts définis dans ce pipeline sont les suivants : \frquote{staging}, \frquote{RC}\footnote{Release Candidate, correspondant à l'environnement de recette client} et \frquote{production}. On considère alors que si le package atteint l'environnement de pré-production, il peut directement être promu en tant que version définitive.

Il y a également un dernier aspect important concernant la gestion des opérations lorsque l'on souhaite mettre en place une démarche \devops : Il s'agit de ne pas viser trop grand dès le début. On peut en effet tout automatiser (montée de version des dépendances automatique, déploiement et provisionnement d'environnement de tests automatiquement\ldots) mais en fonction du besoin et du budget client, tout ne sera pas possible. Il vaut peut-être mieux commencer par ne faire que de l'intégration continue, sans livraison ou déploiement continue, que vouloir construire une chaine d'industrialisation tellement complexe qu'elle ne sera utilisée par personne et aura coutée plus cher que le développement du projet. La matrice en annexe \ref{annexe:devops-matrice} présente bien cela, avec divers niveaux, représentant différentes étapes vers la mise en place d'une démarche \devops.

\subsubsection{Choix des outils}

Une fois que l'on sait comment gérer ses branches, ses versions et que l'on connait les différentes opérations à effectuer pour les différents cas d'usages, il convient de sélectionner les bons outils afin de mener à bien le projet.

Un \gls{SCM} est évidemment obligatoire pour pouvoir effectuer une intégration continue des changements du code, taguer les différentes versions ou encore permettre de séparer le travail en cours avec différentes branches. Plusieurs solutions existent, certaines propriétaires, d'autres open-source ou auto-hébergeables. Parmi les plus populaires, on peut citer \github\footnote{\url{https://github.com}}, Gitea\footnote{\url{https://gitea.io}}, solution auto-hébergeable et économe en termes de ressources ou encore Gitlab\footnote{\url{https://gitlab.com}} qui est utilisé dans le cas des projets de la \naq, auto-hébergé au sein de \onepoint.

Chaque projet va souvent dépendre de dépendances. Dans le cas d'un projet \gls{PHP}, on va souvent retrouver des dépendances via composer, qui sont des dépendances externes. Mais on peut également dépendre de dépendances internes, qui peuvent être des composants réutilisés en interne au sein de plusieurs projets. Il faut alors pouvoir gérer ses dépendances. S'il est possible de déployer ses dépendances internes sur Packagist\footnote{Gestionnaire de dépendances \gls{PHP} - \url{https://packagist.org/}}, il se peut que l'on souhaite garder la main sur ses dépendances, ou ne pas les rendre publiques, et que l'on souhaite donc les garder sur un gestionnaire de paquets privés. Dans le cas de la \naq, c'est l'\gls{artifactory} de Jfrog\footnote{Gestionnaire de fichier binaire - \url{https://jfrog.com/artifactory/}} qui est utilisé afin de gérer ses dépendances. Concrètement, cela consiste à ajouter un repository\footnote{dépôt} au fichier de définition des dépendances (dans le cas de \gls{PHP}, il s'agit d'un fichier appelé \frquote{composer.json}).

Il est ensuite nécessaire, pour pouvoir effectuer de l'intégration continue, de disposer d'un serveur\ldots{} D'intégration continue. De nombreux outils existent, chacun se démarquant avec ses propres fonctionnalités. Les plus connus sont TravisCI\footnote{\url{http://travis-ci.org/}} qui est souvent utilisé lors de projets étant versionné sous \github, TeamCity\footnote{\url{https://www.jetbrains.com/teamcity/}} qui après ses \gls{IDE}, propose également son propre outil d'intégration continue. Finalement, le leader reste Jenkins\footnote{\url{http://jenkins.io/}}. Tous permettent de réaliser de l'intégration continue, mais proposent souvent plus, tel que la livraison ou encore le déploiement continu, le tout selon les besoins \& le budget du client.

\subsubsection{Intégration continue}

Le but de l'intégration continue est d'intégrer les changements des \emph{Dev} et de les tester, à chaque nouvelle modification du code. Pour cela, on utilise un logiciel s'exécutant sur un serveur, connecté au \gls{SCM} contenant le code. Dès qu'une modification de code est poussée sur le \gls{SCM}, un \gls{webhook} est envoyé à l'outil d'intégration continue (par exemple Jenkins \cite{jenkins-guide}) qui va alors dérouler un certain nombre d'étapes définies (installation des dépendances, exécutions des tests\ldots) pour vérifier que l'application est conforme aux demandes clients. Ces retours doivent être rapides afin que les développeurs puissent s'assurer qu'il n'y a pas d'erreurs bloquantes dans leur code.

On peut alors découper l'intégration continue en deux étapes. La première serait \textbf{le build continu}, qui consiste à fournir un retour rapide aux développeurs. Son temps d'exécution doit être de l'ordre de quelques minutes maximum, c'est pourquoi on se contente souvent de lancer seulement les tests unitaire. On retrouve l'illustration de ce flux de travail dans l'annexe \ref{annexe:build-continu}. Il est également possible d'effectuer une analyse statique du code afin de détecter certaines erreurs qui ne seraient normalement détectées qu'à l'exécution du code\footnote{cela s'applique aux langages interprétés, tel que \gls{PHP}}. En \gls{PHP}, il est possible d'utiliser PHPStan\footnote{PHP Static Analysis Tool - \url{https://github.com/phpstan/phpstan}} afin de s'assurer que le code soit syntaxiquement correct, comme on peut le voir en exemple dans l'annexe \ref{annexe:php-error}.

Une autre étape importante de l'intégration continue est la phase de \textbf{qualimétrie}. Il s'agit d'un job\footnote{ensemble d'étapes qui vont être exécutées sur le serveur d'intégration continue} qui va être exécuté une fois par jour, en général la nuit\footnote{lorsque l'activité sur le projet est faible}. Le projet va alors être construit en récupérant les dernières sources disponibles sur la branche de développement. On va ensuite exécuter les tests unitaire, des tests de qualimétrie, tel que des outils de détection de code  copier-coller\footnote{En \gls{PHP}, il existe PHPCPD qui répond à ce besoin - \url{https://github.com/sebastianbergmann/phpcpd}} qui pourraient indiquer des \glsplural{code-smell} et on va exécuter les tests d'intégration, qui peuvent nécessiter le provisionnement d'une base de données et être plus long à exécuter que les tests unitaire. Une fois tous ces tests effectués, on va générer un rapport et le mettre à disposition des équipes de développement qui pourront le consulter le lendemain à leur retour et prendre en compte les remarques du rapport. 

Dans le cas des projets sur la \naq{}, il a été mis en place un autre test qui intervient lors de la phase de qualimétrie et qui permet d'attester que les mises à jour se déroulent correctement. Chaque nuit, la dernière version de la branche de développement est récupérée avec la dernière sauvegarde de la base de données de pré-production. On restaure alors cette base de données sur une base de données temporaire et on vient jouer toutes les mises à jour de schéma, ainsi que les différents hooks de mise à jour\footnote{Dans le \gls{cms} \gls{drupal}, les \frquote{hooks update} permettent de définir des mises à jour à jouer afin de mettre à jour des schémas où effectuer des tâches de migration lors d'une livraison}. Cela permet de tester dans un environnement isolé que les mises à jour de schéma ne viennent pas entrainer de régression ou erreur. Cela ne garantit néanmoins pas qu'elles sont fonctionnelles mais permet de s'assurer de leur bonne exécution.

Bien que l'intégration continue ne permette pas de déployer une application, elle permet de mesurer la qualité de cette dernière et par conséquent, la potentielle difficulté (ou facilité) à livrer et déployer l'application. Les métriques collectées peuvent être nombreuses et indiquer des axes d'améliorations divers.

\begin{itemize}
	\setlength\itemsep{0em}
	\item Le nombre de tests OK / KO peut permettre d'indiquer la stabilité de l'application.
	\item Si l'installation des dépendances échoue, on est tout de suite au courant que le commit ayant changé les dépendances a entrainé cette régression.
	\item Un score élevé de copier-coller au sein d'une application peut indiquer des \gls{code-smell} potentiels, voir une erreur dans la structure de l'application.
	\item De même, l'analyse de code statique permet de relever des erreurs et avertissements sur lesquels il est bon d'avoir des points d'attention, même s'il peut parfois s'agit de faux positifs.
\end{itemize}

\subsubsection{Livraison continue}

Si l'intégration continue permet d'attester de la qualité du code et détecte des potentielles régressions avant leur livraison, la livraison continue permet quant à elle d'obtenir un livrable (souvent un binaire, tel qu'une archive) qui va permettre de déployer à tout moment l'application. 

On va alors construire périodiquement l'application au sein d'un job dédié, qui va récupérer les dernières sources du code de la branche de développement, installer les dépendances, effectuer les divers tests décrits précédemment et construire le livrable contenant ainsi toutes les dépendances de l'application. On pourrait très penser qu'il n'est pas nécessaire d'inclure les dépendances de l'application dans le livrable et que l'on pourrait se contenter de les installer lors du déploiement. Bien que cela soit possible et parfois pratiqué, c'est une pratique déconseillée puisqu'elle implique de faire confiance à un élément qui ne peut être considéré comme digne de confiance : Internet. 

Comment garantir que la version demandée de cette dépendance externe va bien être récupérée ? Qu'il ne va pas y avoir d'interruptions réseaux ? Que le proxy ou pare-feu va autoriser la connexion pour télécharger des dépendances externes ? Toutes ces questions ne peuvent être garanties. Quant bien même les téléchargements des dépendances seraient réussis, cela nécessiterait de vérifier les \gls{checksum} de chaque dépendance pour être sûr qu'il n'y a pas eu de corruption de données. Cela augmenterait le temps de déploiement et ajouterait de potentielles erreurs, entrainant des retours en arrières forcés qui aurait pu être évités s'ils avaient été détectés plus tôt. Le fait de construire le livrable avec ses dépendances avant sa livraison garantit que les dépendances résolues à un instant T sont fiables (vérification de \gls{checksum}) et garantit que le livrable est installable, normalement, sans erreurs. Une fois le livrable construit, on va générer un \gls{checksum} de l'archive générée et c'est ce \gls{checksum} qui sera vérifié lors du déploiement. Si lors du déploiement, l'archive dispose d'un \gls{checksum} valide, alors les dépendances sont valides. C'est du temps processeur\footnote{un seul \gls{checksum} au lieu de 1 par dépendance} et de la bande passante\footnote{on ne télécharge les dépendances qu'à la construction de l'archive et non à chaque déploiement} qui sont économisées et c'est une confiance supplémentaire dans le livrable.

On va ensuite pouvoir déposer ce livrable unique\footnote{Comme indiqué dans la sous-partie \frquote{\nameref{gestion-de-version}} page \pageref{gestion-de-version}} sur un espace de stockage en attendant son déploiement, par exemple sur un \gls{artifactory} et utiliser une notion de \textit{promotion} pour déterminer l'état de ce livrable. Ce système de promotion permet de déterminer si le livrable a été déployé sur un environnement ou non. Dans le cas des projets de la \naq, il y a 3 niveaux de promotions, comme on peut le constater sur l'annexe \ref{annexe:release-naq} : le niveau \frquote{staging}, qui correspond à un environnement de test interne, celui de \frquote{recette client} et enfin celui de \frquote{production}, qui est identique pour la pré-production et la production.

La livraison continue ne permet ainsi pas de déploiement automatique de l'application, mais il est possible de déclencher manuellement le déploiement, qui va alors récupérer le livrable construit précédemment et procéder à son déploiement. Une fois le déploiement terminé, le livrable sera alors promu sur l'\gls{artifactory} selon l'environnement sur lequel la livraison a été effectuée.

Pour prendre les projets de la \naq{} en exemple, le déploiement en recette est fait sous forme de livraison continue. Le paquet est prêt à être livré, mais requiert une validation manuelle pour pouvoir être déployé comme on peut le voir sur l'annexe \ref{annexe:release-naq}. Une fois la validation effectuée, les scripts ansible\footnote{\url{https://www.ansible.com/}} permettent d'effectuer le déploiement du paquet sur le serveur de recette. Si jamais une erreur survient lors du déploiement, elle sera notifiée à Jenkins qui va alors effectuer un retour en arrière et déployer la dernière sauvegarde disponible.

\subsubsection{Déploiement continu}

La différence entre le déploiement continu et l'intégration réside dans l'automatisation du déploiement. La où la livraison continue ne permet pas de déployer de façon automatique, le déploiement continu va permettre de livrer toute version qui passe tous les critères définis : passage des tests, qualité de code\ldots

Cette méthode de déploiement, bien qu'avantageuse puisque les différentes versions se déploient continuellement, peut ne pas être adaptée à toutes les entreprises et tous les besoins. Par exemple, certains clients veulent peut-être attendre, pour des raisons commerciales ou légales, et ne souhaitent donc pas mettre en place ce système. De plus, pour pouvoir effectuer du déploiement continu, il est nécessaire de s'assurer que les tests automatisés soient nombreux et valident les différents cas d'usage de l'application, étant donné qu'il n'y aura pas d'interaction humaine pour le déploiement en production d'une version.

Un des avantages au déploiement continu est que l'on peut, couplé à du monitoring, gérer les montées en charge (les pics de trafic) plus facilement que manuellement puisqu'il suffit alors d'instancier et de provisionner alors un nouvel environnement puis de répartir le pic de charge sur les différents serveurs. Cela demande une mise en place initiale un peu plus complexe mais permet de mieux supporter des pics de trafic.

Le déploiement continu est donc une extension de la livraison continue, avec un système de promotion automatique sur les différents environnements. Il est alors essentiel de disposer de métriques et d'un monitoring efficace pour être au courant d'éventuels problèmes, comme cela sera évoqué dans la sous-partie \frquote{\nameref{paragraph:monitoring}} (p. \pageref{paragraph:monitoring})

\subsubsection{Gestion de l'infrastructure}

La gestion de l'infrastructure fait également partie de l'automatisation d'un projet. Elle permet de ne plus avoir à configurer à la main ou via des scripts difficile à maintenir les différents serveurs qui représentent l'infrastructure nécessaire pour héberger l'application.

Il suffit désormais de décrire dans fichier texte (\frquote{Dockerfile} pour les \glsplural{conteneur} Docker, des fichiers YML pour les scripts ansible\ldots). On parle alors d'\gls{IaC}. Cela permet de passer d'une configuration manuelle, où l'on pouvait oublier un paquet à installer, un fichier de configuration à renseigner\ldots{} À une infrastructure versionnable dans un \gls{SCM}, permettant ainsi de suivre les évolutions de cette dernière. Il est également plus facile de reproduire l'architecture et donc plus facile de provisionner rapidement de nouveaux serveurs/\glsplural{conteneur}, avec Docker et/ou ansible par exemple.

L'\gls{IaC} peut également s'appliquer sur le serveur d'intégration continue, tel que Jenkins, ou l'on va décrire les différentes étapes des jobs dans des scripts Groovy\footnote{\url{https://groovy-lang.org/}}, permettant ainsi de décrire ce que va effectuer ce job.

\subsubsection{Monitoring}\label{paragraph:monitoring}

Lors de déploiement, de livraison ou d'intégration continue, il est nécessaire de savoir si les déploiements sont complets et de manière générale, comment répond l'application une fois déployée, afin d'être alerté en cas d'erreur ou d'incident.

Il est alors important de mettre en place des logs et du monitoring. Cela peut servir à suivre plusieurs comportements, tel que le taux d'utilisation du processeur par le serveur, son utilisation du disque ou encore sa consommation de mémoire vive.

Ces logs peuvent être le résultat des tâches effectuées par Jenkins, tel qu'on peut le voir sur la figure \ref{fig:jenkins-results}. On distingue alors au premier coup d'œil l'état de l'application et on peut consulter les détails de chaque étape afin de savoir ce qui a réussi/échoué.

\newImage{0.45}{jenkins-results.png}{Métriques sur les résultats des jobs Jenkins}{jenkins-results}

Pour une application web, il est également nécessaire de surveiller les codes retours \gls{HTTP} envoyés pour distinguer les erreurs des utilisateurs (retours \gls{HTTP} 4xx) des erreurs serveurs (retours \gls{HTTP} 5xx) et également surveiller les requêtes \gls{HTTP} valides (retours \gls{HTTP} 2xx). Ce monitoring permet ainsi de détecter les potentielles tentatives d'intrusions (un grand nombre d'erreurs utilisateurs sur un formulaire de connexion peut indiquer une tentative d'accès non autorisée) ou encore des erreurs de l'application (une page spécifique qui retourne constamment des erreurs serveurs est une page sur laquelle il est important de se concentrer puisqu'elle contient sûrement un bug)

Il est également nécessaire de surveiller les logs de l'application en elle-même. Pour cela, \citetitle{12factor} \cite{12factor} recommande d'écrire les logs de l'application sur deux sorties : \frquote{stdout}, qui correspond à la sortie standard et \frquote{stderr} qui correspond à la sortie d'erreur standard. Pourquoi ne pas utiliser des fichiers pour pouvoir écrire ? Car en développement, on souhaite avoir les logs rapidement, en général dans la console d'exécution et en production, on utilise les outils qui exécutent l'application pour pouvoir capturer les logs et les écrire aux endroits souhaités (dans les logs Docker par exemple, ou dans un fichier de logs Apache). Cela permet donc une plus grande interchangeabilité et facilité de suivi des logs. 

Évidemment, il est possible d'être alerté lors d'une erreur présente dans les logs, via des canaux variés qui peuvent être des e-mails, un message sur un canal Mattermost\footnote{\url{https://mattermost.com/}}\ldots{}. De plus, des solutions dédiées au suivi d'erreurs existent, tel que Sentry\footnote{Auto-hébergeable - \url{https://sentry.io/}} qui va permettre de s'intégrer dans le code de l'application via des \gls{SDK} dans de nombreux langages. Cela permet d'obtenir en temps réel les erreurs non traitées qui surviennent dans l'application, avec leur contexte (valeurs des variables déclarées à l'instant ou l'erreur est survenue, pile d'erreur\ldots). Sentry va également s'intégrer avec le \gls{SCM} utilisé (Gitlab ou \github{} par exemple) et créer des issues\footnote{Ticket de suivi d'erreur} afin de garder une trace des erreurs au fur et à mesure et de l'impact que cela a eu sur les utilisateurs (si seulement 10 personnes ont eu cette erreur ou bien 5000 par exemple). 

\subsection{Et la sécurité dans tout ça ?}

Un projet automatisé de A à Z peut être testé intégralement, si la sécurité autour de l'infrastructure d'intégration et de déploiement n'est pas sécurisée, cela peut compromettre le projet tout entier.

En effet, si une application vient à être déployée de façon automatique, il va falloir que les outils déployant et testant automatiquement l'application aient accès aux données de cette dernière. Ces données peuvent parfois contenir des tokens, des clés d'\gls{API}\ldots Il faut alors réfléchir à la façon de sécuriser l'infrastructure. 

Il faut tout d'abord restreindre les accès aux différents outils d'automatisation. Pour cela, on peut se servir d'un pare feu, qui va filtrer les connexions entrantes sur les différents serveurs. On peut également mettre en place une \gls{DMZ}, ce qui permet ainsi de séparer le réseau interne de celui externe, connecté à Internet et qui contient les applications ayant besoin d'être accessible via l'extérieur. En plus de cela, on peut également restreindre les accès aux différentes applications via la mise en place d'un \gls{VPN}, qui permet l'accès aux applications via une connexion sécurisée, comme si l'on était présent sur site et évite ainsi d'avoir à exposer les applications sur Internet. Toutes ces mesures sont valables pour tout type d'application, automatisée ou non. 

Il est également possible de mettre en place un bastion qui permet alors de restreindre les accès \gls{SSH} aux machines pour effectuer des tâches d'administrations. En effet, avec un bastion, on ne peut pas se connecter directement en \gls{SSH} sur les machines hébergeant les applications. Il faut passer par une machine dédiée, exposée à Internet (au contraire des autres, qui sont sur un réseau privé) et dont la sécurité est souvent renforcée. Un des avantages est que l'on peut éteindre le bastion une fois les tâches d'administration effectuées et ainsi couper tout accès \gls{SSH} sur les machines.

\newImage{0.30}{bastion.png}{Illustration d'un réseau avec un bastion -  \citetitle{bastion} \cite{bastion} \url{https://blog.octo.com/le-bastion-ssh/}}{bastion}

On peut (\emph{et l'on doit}) aussi se référer à la documentation des outils d'automatisation utilisés. Par exemple, la documentation de Jenkins\footnote{\url{https://jenkins.io/doc/}} ainsi que le livre numérique \citetitle{jenkins-guide} \cite[chapitre 7, Sécuriser Jenkins]{jenkins-guide} décrivent les façons de sécuriser l'outil et éviter ainsi que le serveur d'intégration et de déploiement continu ne servent de vecteur d'attaque pour compromettre l'application (\emph{ou pire, l'entreprise entière, étant donné qu'un système d'intégration continu est souvent utilisé pour plusieurs projets}). Une des premières mesures est de restreindre les accès utilisateurs, en appliquant le principe de moindre privilège (voir \citetitle{anssi-least-privilege} \cite{anssi-least-privilege}). Cela signifie donner uniquement les droits strictement nécessaires. Si un utilisateur a simplement besoin de consulter les rapports, il n'y a pas d'intérêt de lui donner les droits pour pouvoir éditer la configuration permettant de générer ces derniers.

Concernant les interactions entre le serveur d'intégration continue, \gls{SCM} et les différents serveurs, il peut être nécessaire de créer un compte de service (\emph{compte système, n'étant relié à aucun utilisateur et disposant des droits minimaux pour l'exécution de la tâche pour lequel il est utilisé}) avec des accès par clé \gls{SSH} utilisés pour les déploiements. L'utilisation d'une clé \gls{SSH} plutôt qu'un mot de passe est obligatoire puisque la demande de mot de passe se fait de façon interactive (et requiert donc une intervention utilisateur)\footnote{Même s'il est possible de contourner ce fonctionnement, par exemple avec sshpass, il est recommandé d'utiliser des clés \gls{SSH}}. De même, l'accès aux serveurs doit être limité et surtout contrôlé. Il faut ainsi préférer des comptes nominatif pour les personnes intervenant manuellement sur le serveur, même si leur création peut s'avérer plus fastidieuse plutôt qu'un seul compte administrateur partagé entre les membres de l'équipe. Ainsi, si un compte vient être compromis, il est plus facile de révoquer ses accès plutôt que de bloquer l'accès à tous les membres de l'équipe.

Finalement et comme on peut le lire dans \citetitle{jenkins-security} \cite{jenkins-security}, il est important de savoir les limites de l'outil. Il est également important d'en maitriser la distribution des accès, sous peine de se retrouver à donner des accès privilégiés à une personne à qui l'on pensait simplement donner des droits d'exécution. L'exemple donné dans cet article\footnote{L'exemple résumé est le suivant : contourner le fonctionnement d'une demande d'interaction utilisateur pour pouvoir exécuter des commandes sur le serveur, dans une boucle, ce qui revient alors à disposer d'un terminal} est totalement valable, puisqu'un développeur qui peut renseigner des paramètres avant (ou durant) l'exécution d'un job peut tout à fait y inclure des commandes, qui peuvent potentiellement être exécutées et amener à des fuites de secrets, identifiants ou mot de passe\ldots{} 

Concernant les applications web, l'organisation \gls{OWASP}\footnote{\url{https://www.owasp.org}} est reconnue pour ses conseils et bonnes pratiques dans le domaine de la sécurité. Elle fournit des outils afin de tester ses applications lors de leur développement (tel que ZAP\footnote{Zed Attack Proxy} qui permet de détecter automatiquement les vulnérabilités connues lors du développement d'applications web) ou encore des listes de bonnes pratiques tel que par exemple les dix failles de sécurité les plus communes dans un projet et comment s'en prémunir\footnote{\url{https://www.owasp.org/index.php/Category:OWASP_Top_Ten_Project}}
