\subsection{Gestion de projet}

\epigraph{\frquote{Avoir 300 personnes dans une cuisine pour faire un ≈ìuf au plat ne permettra pas de servir le plat 300 fois plus vite}}{Analogie de la \frquote{Loi de Brooks\footnote{\url{https://fr.wikipedia.org/wiki/Loi_de_Brooks}}}}

\subsubsection{Partie financi√®re}
L'automatisation d'un projet ne peut s'effectuer un en jour. De m√™me que la citation ci-dessus fait sens, la migration d'un projet existant vers une automatisation totale ne peut s'effectuer en un jour, m√™me en mobilisant de grand moyens. Il est donc n√©cessaire de pr√©parer et planifier une conduite du changement qui permettra d'accompagner tous les acteurs du projet, afin que la transition s'effectue dans les meilleurs conditions possible. Cela passe d'abord par une r√©flexion sur la conduite √† adopter et les changements √† apporter. 

Prenons pour exemple un projet fonctionnel depuis maintenant plusieurs mois. Le projet a d√©j√† √©t√© livr√© (avec plus ou moins de difficult√©) quelques fois en production. Comment convaincre que l'automatisation va apporter du bien √† ce projet‚ÄØ? Qui est-il n√©cessaire de convaincre‚ÄØ?

Tout d'abord, il faut convaincre les personnes responsables financi√®rement du projet. En effet, il est possible d'avoir un projet automatis√© de A √† Z, si ce processus d'automatisation vient √† co√ªter 3 fois le prix total vendu au client, aucun responsable ne vous donnera son accord. Il va √©galement falloir convaincre les personnes responsables du projet (chef de projet, directeur de projet...) qu'il y a un int√©r√™t √† effectuer cela. En effet, sans garantie que ce processus pourra amener quelque chose de positif, peu laisseront une opportunit√© d'essayer d'automatiser un projet.

Il faut ainsi pr√©parer son argumentaire, avec les bienfaits que cela pourra obtenir sur les \gls{KPI} et sur la vie du projet √† moyen/long terme.

\begin{description}
	\setlength\itemsep{0em}
	\item [La dur√©e de de d√©ploiement] peut √™tre r√©duite pour permettre de se concentrer sur d'autres probl√©matiques. De plus, si les temps de d√©ploiement sont r√©duits, cela signifie que les temps d'interruption de service pourront √™tre r√©duit lors des livraisons.
	\item [Erreur de d√©ploiement] Si les d√©ploiements sont automatis√©s, les risques d'incidents lors des d√©ploiements, souvent du √† des erreurs humaines, seront alors r√©duit.
	\item [Rentabilit√© financi√®re] Prenons une t√¢che qui co√ªte \numprint{3000}‚Ç¨ √† r√©aliser toutes les 3 semaines. Son co√ªt est donc assez √©lev√©. Le fait d'automatiser cette t√¢che permettra d'√©conomiser de l'argent sur la dur√©e. Si le fait d'automatiser cette t√¢che co√ªte par exemple, \numprint{10000}‚Ç¨, un gain sera per√ßu d√®s la 12\up{√®me} semaine.
	\item [Part de march√©] Si les d√©ploiements sont plus fiables et rapides, que la rentabilit√© financi√®re du projet est √©galement florissante alors il sera possible de concentrer les efforts sur des fonctionnalit√©s √† forte valeurs ajout√©es qui permettront ainsi de se d√©marquer de la concurrence et d'augmenter les parts de march√© √† moyen/long terme.
	\item [\Gls{timetomarket}] Dans un environnement tr√®s concurrentiel, il est essentiel de pouvoir intervenir rapidement. R√©duire la dur√©e entre la naissance d'une id√©e/besoin et sa mise en production est important, sous peine de voir des concurrents prendre des parts de march√©. L'automatisation peut alors permettre de d√©ployer rapidement et avec confiance les d√©veloppements r√©alis√©s.
	\item [Reprise d'activit√©] Il s'agit ici de d√©montrer que le produit parfait n'existe pas. Il arrivera que l'application soit hors ligne √† cause d'un incident ou qu'une mise √† jour entraine une interruption de service. En revanche, si l'on ne peut √©viter l'incident √† un moment donn√©, il est capital de pouvoir restaurer l'application dans des court d√©lai et ce de fa√ßon certaine. Disposer d'un \gls{PCA} ou d'un \gls{PRA} int√©grant une automatisation de la reprise d'activit√© est un atout non n√©gligeable qui permettra une reprise de l'activit√© au plus vite. On peut alors passer d'une interruption de plusieurs heures √† une se comptant en minutes.
\end{description}

\subsubsection{Organiser le flux de travail}
Il est √©galement n√©cessaire de planifier au mieux les dur√©es des travaux √† accomplir afin d'√©viter des d√©passements dans les d√©lais annonc√©s. Cela implique donc de r√©fl√©chir au temps n√©cessaire √† investir et aux diff√©rents jalons qui valideront la bonne mise en place de l'automatisation. 

Pour pouvoir mettre en place une d√©marche d'automatisation sur un projet, il est n√©cessaire que ce dernier soit assez mature pour pouvoir s'y adapter. Ainsi, comme l'indique \citetitle{phoenixProject} \cite{phoenixProject},  avant de se lancer dans une d√©marche d'automatisation (\emph{ou plus globalement, pour pouvoir g√©rer correctement un projet}), la premi√®re √©tape est de savoir g√©rer le flux de travail.

Le flux de travail, ce sont les diff√©rentes t√¢ches qui sont √† r√©aliser sur le projet. Ces derni√®res sont souvent des stories (\emph{dans le cas d'une m√©thodologie agile}), d√©finies conjointement avec le client et correspondent ainsi √† ce qui a √©t√© d√©fini dans le cahier des charges. L'inconv√©nient est que ce flux de travail est fragile. Il peut rapidement d√©river et se retrouver surcharger, surchargeant ainsi les √©quipes. Le principal ennemi de flux de travail est le travail non pr√©vu (\emph{unplanned work}). Ce sont toutes les petites t√¢ches non pr√©vues, qui prennent 10 √† 15 minutes, qui ne sont suivies nulle part et qui mises bout √† bout peuvent faire perdre plusieurs jours de travail et √©puiser les √©quipes, qui ne voit jamais le travail diminuer.

Quelles sont donc les solutions pour g√©rer ce travail non pr√©vu ? L'objectif est ici de faire en ce sorte que ce travail non pr√©vu ne soit plus ex√©cut√© directement sans passer par une phase minimale de planification. Pour cela, il est possible de mettre en place des kanbans. Qu'est ce qu'un Kanban ? Il s'agit d'une m√©thode de repr√©sentation des t√¢ches qui permet de visualiser l'avanc√©e du projet en temps r√©el (\emph{ou du moins, √† chaque fois que le tableau est mis √† jour}). On peut ainsi limiter le travail non pr√©vu, en l'ajoutant √† une cat√©gorie d√©di√©e, le \emph{backlog}, qui correspond √† la pile de t√¢che √† r√©aliser. Une fois ces t√¢ches estim√©es, d√©coup√©es et discut√©es avec le client, elles peuvent √™tre consid√©r√©es comme pr√™te √† √™tre commenc√©es. On parle alors de \emph{D√©finition Of Ready}. De m√™me, pour d√©terminer qu'une t√¢che a √©t√© termin√©e par l'√©quipe de d√©veloppement et donc pr√™te √† √™tre livr√©e, on parle de \emph{Definition Of Done}, ce qui correspond √† une liste de points, √©tabli par l'√©quipe en interne. Ces points correspondent √† des √©l√©ments √† v√©rifier et √† cocher pour indiquer si une t√¢che est vraiment termin√©e ou non. On peut y retrouver par exemple l'√©criture de tests ou encore le fait qu'une autre personne ai relu le code, le fait que la documentation ait √©t√© mise √† jour\ldots

%\newImage{0.35}{kanban.jpg}{Repr√©sentation d'un tableau Kanban -  \url{https://commons.wikimedia.org/}}{kanban}

On peut ensuite suivre l'√©volution des t√¢ches dans leur diff√©rentes √©tapes, du d√©veloppement √† leur livraison, en passant par les tests. Ainsi, le travail non pr√©vu ne peut plus d√©ranger un sprint en cours puisqu'il est possible de d√©finir des limites, en disant par exemple que seules les t√¢ches √©tant pr√™tes seront travaill√©es dans ce sprint et que les autres devront attendre le prochain sprint pour pouvoir √™tre trait√©es. N√©anmoins, il s'agit de faire attention √† un point en mettant en place un kanban. En effet, si l'on met simplement en place un kanban et que l'on continue de traiter les t√¢ches comme elles l'√©taient pr√©c√©demment, on s'expose au risque de voir le travail en cours, ou \emph{WIP\footnote{Work In Progress}} s'accumuler. Cela risque donc de ralentir les √©quipes voir de les d√©motiver. De plus, si tous le travail est en WIP, il n'y a aucune fa√ßon de savoir depuis combien de temps un t√¢che est pr√©sente ici, ce qui fait que certaines t√¢ches peuvent tr√®s bien rester en WIP pendant des jours voir des semaines. La solution √† ce probl√®me tient dans le fait de limiter le travail en cours. En effet, en limitant le travail en cours, on s'assure que les t√¢ches ne resteront pas √©ternellement en attente. Les t√¢ches bloqu√©es pourront √©ventuellement √™tre pass√©es dans une colonne "Bloqu√©"\footnote{Cette colonne devra elle aussi √™tre limit√©e en √©l√©ments, sous peine de seulement d√©caler le soucis !}. De plus, si le travail en cours est restreint, il sera de meilleur qualit√©, puisque moins dispers√© et donc engendrera moins de bug‚ÄØ!

\subsubsection{Livrer plus rapidement de la valeur m√©tier}
L'un des objectifs de l'automatisation est √©galement de faciliter le passage d'un syst√®me o√π l'on met plusieurs mois avant de livrer une grosse fonctionnalit√© √† un autre o√π l'on livre de multiples petites fonctionnalit√©s. Attendre plusieurs mois pour livrer une fonctionnalit√© peut en effet avoir des effets ind√©sirables.

\begin{itemize}
	\setlength\itemsep{0em}
	\item Dans une √©poque hyper-concurrentielle o√π l'on veut tout, toujours plus vite, certains besoins sont √©ph√©m√®res ou n√©cessite un \gls{timetomarket} faible pour se d√©marquer de la concurrence. Si l'on livre la fonctionnalit√© une fois le besoin pass√©, la fonctionnalit√© n'a plus de sens. Cela vaut aussi si l'on vient √† livrer un produit une fois que tous les concurrents sont d√©j√† positionn√©s dessus. Il vaut mieux livrer petit √† petit des parties du besoin pour pouvoir l'am√©liorer continuellement.
	\item Une fonctionnalit√© qui met longtemps √† √™tre livr√©e induira un stress au niveau des √©quipes, qui auront sur leurs √©paules la responsabilit√© de livrer \emph{la fonctionnalit√© parfaite}, plut√¥t que livrer plusieurs petites fonctionnalit√©s.
	\item Le risque d'√©chec est beaucoup plus important en livrant une fonctionnalit√© plut√¥t que plusieurs petites, surtout si des changements d'architecture (\emph{Structure de la base de donn√©es, ajout de nouveaux composants...})
	\item Plus l'on attend longtemps pour livrer une fonctionnalit√©, plus on prend le risque de se retrouver dans le cas d'un \emph{effet tunnel} ou la compr√©hension de ce qui √©tait √† faire s'est retrouv√©e au fur et √† mesure du temps par √™tre l'oppos√© de ce qui √©tait demand√©. Dans cette position, le client et le chef de projet communique souvent peu, l'√©quipe de d√©veloppement travaille en g√©n√©ral sans avertir de ses avanc√©es,\ldots Seule la date limite permet de voir ce qui a √©t√© r√©alis√© et il s'agit plus souvent d'un √©chec que d'une r√©ussite.
\end{itemize}

Cette volont√© de vouloir livrer plus petit mais plus r√©guli√®rement s'inscrit dans \emph{l'am√©lioration continue}. Au d√©but, la fonctionnalit√© ne sera peut-√™tre pas parfaite, mais elle sera continuellement am√©lior√©e jusqu'√† correspondre au besoin voulu. 

\newImage{1}{devops-objective.jpg}{Mise en place de l'am√©lioration continue entre \emph{Dev} et \emph{Ops} - \url{https://itrevolution.com}}{devopsObjective}

N√©anmoins, il convient de v√©rifier que ce syst√®me est int√©gr√© et accept√© par l'√©quipe, sous peine de voir un rejet de cette m√©thodologie et d'entrainer des conflits internes dans les √©quipes. Cela peut √™tre le cas avec certaines personnes r√©fractaires au changement, par exemple des d√©veloppeurs √¢g√©s, proche de le retraite, qui n'ont peut-√™tre pas envie de se reformer et s'adapter √† de nouvelles m√©thodes de travail et qui tenteront de garder leurs habitudes. Cela peut √©galement provenir de personnalit√©s avec un fort caract√®re qui pensent que leur m√©thode est plus efficace que les autres ou encore de bien d'autres cas. De mani√®re g√©n√©rale, les personnes ne souhaitent pas sortir de leur zone de confort. Pour permettre ce changement, il va falloir exposer les diff√©rents avantages aux √©quipes et leur montrer les int√©r√™ts qu'ils ont √† s'essayer √† cette m√©thode pour peut-√™tre finir par l'adopter de leur plein gr√©. 

Afin de faire int√©grer ce syst√®me par une √©quipe, il faut tout d'abord trouver des personnes qui sont ouvertes au changement, des \glsplural{earlyadopter} qui ont envie de voir cette am√©lioration se mettre en place. Dans l'id√©al, ces personnes seront √©galement des personnes influentes vis-√†-vis des autres afin de permettre une meilleure int√©gration du changement par le suite. Il faut ensuite convaincre une majorit√© de personne et les amener vers ce changement. L'id√©e est de construire une base plus importante de personnes souhaitant voir cette √©volution se mettre en place afin de ne laisser que les personnes r√©fractaires au changement √† g√©rer par la suite, quitte √† les mettre devant le fait accompli une fois une majorit√© de personnes convaincue. On peut voir cette mise en place de la culture \emph{DevOps} d√©taill√©e dans \citetitle{devOpsHandbook} \cite[p.58-59]{devOpsHandbook}.

\subsubsection{Retours et apprentissage continu}

L'un des premiers avantages si l'on met en place une d√©marche d'automatisation est une meilleure communication entre les d√©veloppeurs, √©galement appel√©s \emph{Dev}, et les administrateurs syst√®mes, appel√©s \emph{Ops}. Si l'on met en place une d√©marche d'automatisation, un besoin de m√©trique va √™tre n√©cessaire. Ces m√©triques, semblables aux \gls{KPI} pr√©c√©demment d√©taill√©s, permettront de savoir par exemple le temps de d√©ploiement de l'application, les derniers bugs remont√©s, les suivis de performance afin de d√©terminer si une requ√™te \gls{SQL} est trop lente ou non... Ces m√©triques, conjointement d√©finies par les \emph{Devs} et les \emph{Ops} vont permettre d'obtenir des retours rapides sur l'√©tat de l'application et ainsi de pouvoir am√©liorer le produit plus facilement, en corrigeant les bugs au plus t√¥t. C'est la base de la \emph{Second Way}, ou deuxi√®me √©tape, comme expliqu√© dans \citetitle{phoenixProject} \cite[p.405-410]{phoenixProject}.

Un autre point √† prendre en compte lors d'une d√©marche d'automatisation est l'apprentissage continu. Comme nous l'avons vu dans la partie pr√©c√©dente, \etsy a mis en place un outil de post-mortem (p.\pageref{post-mortem}) qui permet de savoir les erreurs rencontr√©es dans le pass√© et de permettre qu'elles ne se reproduisent plus. Cette notion constitue la \emph{Third Way} mais ne se limite pas seulement aux erreurs rencontr√©es. Avec le temps obtenu par l'automatisation, il est ainsi possible de s'am√©liorer sur d'autres points : partager les connaissances de chacun pour faire progresser l'√©quipe et les personnes la constituant, documenter et am√©liorer l'int√©gration de nouvelles personnes dans les √©quipes ou les environnements de travail\ldots{} L'√©quipe sera alors plus performante et pourra ainsi d√©livrer de meilleurs produits.

% TODO Le temps lib√©r√© par l'automatisation des t√¢ches peut permettre de souder les liens d'une √©quipe et d'am√©liorer les relations de cette derni√®re. Cela lib√®re du temps pour du team building par exemple. Un sujet technique qui rapproche en terme d'humain

\subsection{Environnement de d√©veloppement}

L'environnement de d√©veloppement est le premier environnement o√π sont d√©velopp√©es les diff√©rentes fonctionnalit√©s du projet. Ce cadre de travail doit pouvoir √™tre install√© rapidement afin de se concentrer sur le d√©veloppement de fonctionnalit√©s et non sur l'installation de l'environnement de travail.

\subsubsection{Arriv√©e sur le projet}

Plusieurs personnes sont potentiellement amener √† travailler sur le projet. Il est donc important de documenter l'installation et les pr√©-requis afin de pouvoir commencer √† travailler. Il n'est malheureusement pas rare de voir des projets o√π la documentation du projet est faible, voir inexistante.

L'id√©al pour un d√©veloppeur qui vient d'arriver sur un projet serait de disposer d'un environnement pr√™t √† l'emploi, qui puisse se lancer en quelques commandes (installation des d√©pendances et provisionnement de l'environnement). Des outils de conteneurisation tel que Docker\footnote{\url{https://www.docker.com/}} permettent ainsi d'avoir des environnements isol√©s et reproductibles quelque soit l'environnement du d√©veloppeur. De plus, avec Docker, l'architecture du projet est repr√©sent√© sous forme textuelle et donc int√©grable dans le \gls{SCM}, ce qui permet de savoir les √©volutions sur l'architecture du projet facilement. On parle alors d'\gls{IaC}. De plus, un projet qui peut s'installer rapidement signifie qu'un d√©veloppeur peut √™tre efficient plus rapidement sur son projet. Il peut ainsi apporter ses comp√©tences sur de r√©elles probl√©matiques plut√¥t qu'√™tre bloqu√© pendant de longues heures √† chercher comment installer ledit projet.

Afin de permettre un d√©marrage rapide, il est √©galement commun de mettre des alias sur les commandes les plus utilis√©es lors des d√©veloppements. Par exemple, si une commande permettant d'effacer le cache de l'application est longue √† taper, on la raccourcira en quelques chose tel que \frquote{make clear} par exemple. Pour cela, plusieurs solutions sont disponibles: les scripts \gls{PHP} dans le cas d'un projet \gls{PHP} ou encore l'utilisation des Makefile, permettant de construire les logiciels et leur d√©pendances et d'y effectuer des t√¢ches diverses, d√©finies dans un fichier. Il est √©galement possible d'√©crire des scripts shell, permettant d'effectuer des t√¢ches plus complexe\footnote{Comme faire le caf√© ? \emoji{üòä} - \url{https://github.com/NARKOZ/hacker-scripts}}

De plus, il est souvent n√©cessaire d'avoir des configurations sp√©cifiques sur les environnements de d√©veloppements. En effet, dans un contexte de d√©veloppement, on va vouloir obtenir les erreurs imm√©diatement, dans un terminal par exemple, alors que dans un environnement de production, ces derni√®res seront dans un fichier de log. De plus, on va pouvoir vouloir tracer le temps que prend chaque requ√™te vers une base de donn√©es ou encore disposer d'outils permettant de mettre des points d'arr√™ts dans le code afin de pouvoir d√©bugger lors des phases de d√©veloppements. Il faut donc des moyens d'activer ses outils simplement. Cela peut passer par des scripts ou encore des images Docker d√©di√©es au d√©veloppement, bas√©e sur celle de production. Le but est d'obtenir un environnement le plus proche possible de la production tout en ayant la possibilit√© d'ajouter des outils de d√©veloppements additionnels.

\subsubsection{Build local}

Le build local correspond √† la premi√®re boucle de retour au d√©veloppeur. C'est dans cet environnement qu'il obtient des retours rapide, que cela soit sur ses tests unitaire, ses √©ventuelles fautes de frappe, erreur de syntaxe\ldots. L'objectif de ce build local est de d√©tecter les erreurs au plus t√¥t, pour √©viter qu'elle ne soient potentiellement oubli√©es et non d√©tect√©es par les autres √©tapes du flux de travail et provoque un bug en production alors qu'il aurait pu √™tre √©vit√© simplement (dans le cas d'une erreur de syntaxe). Plusieurs solutions peuvent alors √™tre mise en place pour am√©liorer ce build local.

\paragraph{L'utilisation d'un IDE}

L'objectif de l'\gls{IDE} est de fournir un support de travail au d√©veloppeur et de lui rep√©rer de fa√ßons automatique des erreurs d'inattention. Il convient alors de se familiariser avec un \gls{IDE} afin de tirer le maximum de ce dernier. Parmi les fonctionnalit√©s communes d'un bon \gls{IDE}, on retrouve :

\begin{itemize}
	\setlength\itemsep{-0.5em}
	\item D√©tection des erreurs de syntaxe
	\item Ajout automatique des imports dans un fichier
	\item Lancement automatique des tests unitaire √† la sauvegarde/modification d'un fichier
	\item Auto-compl√©tion automatique permettant de conna√Ætre le nom des m√©thodes et fonction √† la saisie
	\item Indenter le code selon des conventions d√©finies
	\item Affichage des erreurs communes simple √† d√©tecter (tel qu'un code non atteignable car apr√®s un retour de fonction par exemple)
\end{itemize}

Les \gls{IDE} disposent souvent de plugins qui permettent d'√©tendre leurs fonctionnalit√©s pour pouvoir am√©liorer le quotidien du d√©veloppeur. Par exemple, certains plugins vont permettre de g√©rer l'affichage de l'√©tat de la base de donn√©es, s'interfacer avec l'√©tat des outils d'int√©grations continue distants (via les \gls{API} de ces derniers) afin de savoir si les tests d'int√©grations sont pass√©s ou non\ldots

\paragraph{Les hooks du SCM} Git, \gls{SCM} utilis√© de fa√ßon majoritaire dans les d√©veloppements dispose d'un m√©canisme permettant d'√©tendre ses fonctionnalit√©s : les hooks. Ces hooks, tel que d√©crits dans la documentation (\citetitle{git-hook} \cite[chapitre 8.3]{git-hook}) permettent de lancer des scripts √† certaines √©tapes, tel qu'avant un commit, avant de pousser le code sur le serveur, apr√®s r√©ception des modifications du serveur\ldots{} Cela permet souvent de v√©rifier que les tests unitaires passent, qu'il n'y a pas d'erreur de syntaxe ou encore que le linter\footnote{analyse de code statique permettant de d√©tecter les erreurs communes, et d'instaurer une syntaxe (r√®gles d'espacement, nommage des variables\ldots) commune} ne g√©n√®re pas d'erreur

\paragraph{Le pair programming (programmation en bin√¥me)}

Le pair programming consiste √† d√©velopper √† deux d√©veloppeurs sur le m√™me poste de travail. Bien qu'au premier abord, cela puisse sembler √™tre une perte de temps et d'argent (puisqu'il n'y a au final qu'une seule personne qui tape sur le clavier), cette m√©thode permet de d√©tecter des erreurs plus t√¥t, puisqu'il y a 2 paires d'yeux qui peuvent relever les erreurs au lieu d'une seule. Souvent, il peut arriver un d√©veloppeur seul d'√™tre \frquote{la t√™te dans le guidon}, c'est √† dire qu'il est tellement absorb√© dans son code et peut donc oublier certains cas, certaines r√®gles m√©tiers\ldots{} Le fait de travailler en bin√¥me permet ainsi de d√©celer ces erreurs plus t√¥t et d'assurer une meilleure qualit√© de code. Les deux d√©veloppeurs √©changent rapidement leur r√¥les afin de travailler de fa√ßon efficace et de passer d'observateur √† d√©veloppeur. 

\subsection{L'importance des tests} \label{importance-test}

Les tests ont un r√¥le crucial dans une d√©marche d'automatisation. En effet, lorsque l'on automatise quelque chose, il est essentiel de s'assurer que le comportement de l'application est valide puisque l'on va par la suite d√©ployer automatiquement cette application en production. Selon le \gls{CFTL} et l'\gls{ISTQB}, il existe 4 types de tests et chacun dispose de 4 objectifs formant ainsi une matrice repr√©sent√©e dans le tableau \ref{tab:matrice-test}.


\begin{table}[H]
	\centering
	\begin{adjustbox}{width=0.95\textwidth,center=\textwidth} 
		\begin{tabular}{|l|l|l|l|l|}
			\hline
			\diagbox{type de test}{valide} & Fonctionnement unitaire & R√®gle m√©tier & D√©veloppement & Interaction \\ \hline
			Test de composant     & X                       & X            & X              &             \\ \hline
			Test d'int√©gration    &                         & X            & X              & X           \\ \hline
			Test Syst√®me          &                         & X            &               & X           \\ \hline
			Test d'acceptation    &                         & X            &               &             \\ \hline
		\end{tabular}
	\end{adjustbox}
	\caption{Matrice de tests selon leur type et leur objectif}
	\label{tab:matrice-test}
\end{table}

\subsubsection{Le test de composant}\label{test-composant}

Aussi appel√© \gls{TU}, son objectif est que le composant test√© soit totalement isol√© afin de se concentrer uniquement sur le \emph{fonctionnement unitaire} de ce dernier, sans d√©pendre d'autre composant. On peut alors tester tous les cas, du cas dit \frquote{g√©n√©ral}, qui repr√©sente souvent 80\% des cas, jusqu'aux \frquote{cas limites}, cas apparaissant plus rarement mais pouvant entrainer un comportement non souhait√© de l'application. Cela permet de v√©rifier que le code √©crit par le d√©veloppeur lors de la phase de \emph{d√©veloppement} est bien valide. Ainsi, un test de composant peut valider des \emph{r√®gles m√©tier} et ainsi √©galement correspondre √† un test d'acceptation\footnote{d√©tails sur les tests d'acceptation dans la sous partie \frquote{\nameref{test-acceptation}} (p. \pageref{test-acceptation})}.

Un exemple commun de test de composant est par exemple le test d'une m√©thode de calcul d'une calculette. On dispose d'une m√©thode \frquote{calculer} disposant de 3 param√®tres, 2 \frquote{op√©randes} num√©riques et un \frquote{op√©rateur}. Un cas g√©n√©ral serait alors de tester que \frquote{3+2} retourne bien \frquote{5} et un cas limite serait de tester que \frquote{5/0} l√®ve bien une exception, puisqu'il s'agit d'une op√©ration ill√©gale.

Dans le cas de \gls{PHP}, un exemple de \gls{framework} de test unitaire est PHPUnit\footnote{\url{https://phpunit.de/}}. Le principal avantages de ce type de test est sa rapidit√© : ne n√©cessitant aucune interaction avec des composants externes (ou bien ces composants disposent d'un \gls{mock}), l'ex√©cution des tests est tr√®s rapide.

\subsubsection{Le test d'int√©gration}

Une fois chaque composant test√© unitairement, il convient de v√©rifier que ces composants sont capable d'\emph{interagir} entre eux. En effet, dans la sous-partie pr√©c√©dente, il √©tait indiqu√© que les composants √©taient isol√©s les uns des autres. N√©anmoins, dans de nombreux cas, il est n√©cessaire que des composants interagissent entre eux. On va alors alors utiliser un \gls{mock} afin de simuler le comportement d'un composant, afin de tester l'autre.

Un exemple serait une \gls{API} qui communiquerait avec une base de donn√©es afin de retourner les r√©sultats. Lorsque l'on teste l'\gls{API} unitairement, on ne souhaite pas d√©pendre de la base de donn√©es. On va donc simuler les r√©ponses que nous donnerait la base de donn√©es et envoyer ces donn√©es √† l'\gls{API} qui pourra alors √™tre test√©e.

Cependant, si l'on teste toute notre application de cette fa√ßon, il est impossible d'attester le bon fonctionnement de nos composants entre eux. La version de la base de donn√©es pourrait en effet √™tre incompatible avec le code actuellement utilis√© par l'\gls{API}. Si aucun test d'int√©gration n'est effectu√©, la confiance dans l'application sera bas√©e sur le \gls{mock} de la base de donn√©es et on risque alors de se retrouver dans le cas de la figure \ref{fig:no-integration-test}, avec des composants isol√©s fonctionnant tr√®s bien individuellement mais incapable de s'ex√©cuter ensemble. Cela s'illustre avec la figure \ref{fig:no-integration-test}. Dans ce cas, les tiroirs s'ouvrent tr√®s bien individuellement mais lorsqu'on les assemblent, il n'est pas possible d'ouvrir les deux tiroirs en m√™me temps, puisque le premier bloque l'ouverture du second.

\newImage{0.4}{no-integration-tests.png}{Exemple de tests unitaire sans tests d'int√©gration.}{no-integration-test}

Les tests d'int√©gration vont donc garantir que chaque composant, d√©ploy√© dans l'environnement d'ex√©cution de l'application, est capable de communiquer de fa√ßon correcte avec ses d√©pendances.

\subsubsection{Le test syst√®me}

Les tests syst√®me permettent de tester le comportement de l'application sans forc√©ment avoir connaissance du code. Cela permet ainsi de v√©rifier que l'application effectue bien ce qui est indiqu√© dans les sp√©cifications demand√©es et que les diff√©rents composants interagissent bien entre eux. Ces tests sont √©galement appel√©s \frquote{tests boite noire}. De plus, les tests syst√®mes permettent de v√©rifier que les composants interagissent correctement entre eux, au niveau global de l'application (\emph{au niveau syst√®me}) et non en mettant un composant dans l'application et en regardant son comportement avec les autres composants, comme c'est le cas avec le test d'int√©gration.

Ce sont √©galement les tests qui sont les plus haut niveau, puisqu'il s'ex√©cutent avec toute l'application et ses d√©pendances / composant. On peut par exemple citer les tests \gls{E2E} qui sont des tests syst√®me qui permettent de tester le comportement d'une application en d√©crivant les actions r√©alis√©es sur cette derni√®re (cliquer sur un bouton, r√©duire la fen√™tre) et les r√©sultats attendus.

Le \gls{framework} \gls{angularjs} , par exemple, permet de r√©aliser des tests \gls{E2E} avec Protractor\footnote{\url{https://www.protractortest.org/}}. Cela va ainsi √©muler un navigateur dans lequel il va √™tre possible de d√©crire les comportements utilisateurs. 

Un autre exemple de test syst√®me serait un test de charge, r√©alis√© sur un environnement similaire √† la production, durant lequel on ne va pas tester la conformit√© de l'application mais sa capacit√© √† supporter un certain trafic. Dans le cas d'une application web, cela consiste √† simuler des centaines ou milliers de connexion simultan√©es sur le site afin de v√©rifier sa capacit√© √† r√©pondre convenablement. √âvidemment, tester ceci sur un environnement avec une configuration diff√©rente de la production n'a que peu de sens, puisque le serveur de test sera alors sous-dimensionn√©, sur-dimensionn√© ou disposera d'une gestion du cache diff√©rente par exemple mais dans tous les cas, les r√©sultats seront fauss√©s.

L'avantage de ces tests syst√®mes est qu'il s'agit des tests les plus complets, puisqu'ils permettent de tester le produit fini. L'inconv√©nient est que ces derniers sont plus longs √† ex√©cuter.

%\subsubsection{Campagne de test}
%Parler de Protractor et Squash sur \bv
%Parler de Protractor et Squash sur \bv. Tests automatis√©s unitaires (phpunit) permettant √† la plateforme d'int√©gration continue de v√©rifier la conformit√© du code par rapport aux attentes m√©tiers.

\subsubsection{Le test d'acceptation}\label{test-acceptation}

Souvent r√©alis√© par le client, il va consister, au travers d'une campagne de test g√©n√©ralement manuelle, √† v√©rifier que les \emph{r√®gles m√©tiers} sont bien respect√©es. Le client peut n√©anmoins d√©cider de d√©l√©guer ce test √† une √©quipe qualit√©, ou √† un prestataire externe.

Il est n√©anmoins possible que certain test d'acceptation soit valid√© en amont, comme l'exemple de la calculatrice donn√© dans la partie \frquote{\nameref{test-composant}} (p. \pageref{test-composant}) qui va valider la \emph{r√®gle m√©tier} (effectuer une op√©ration) tout en validant le bon fonctionnement du code et ses cas limites.

\subsubsection{Les tests par mutation et chaos engineering}

\todo[color=gray]{Partie bonus test mutation / chaos engineering √† eventuellement traiter}

Ces deux pratiques viennent compl√©ter les batteries de tests existant afin de garantir que le syst√®me, et l'application puissent r√©agir √† tout instant, en venant volontairement modifier le code ou endommager un serveur ou param√®tre sur le serveur de l'application afin de constater comment r√©agit cette derni√®re.

\subsection{Int√©gration, d√©ploiement et livraison continue}

Une fois que les tests permettent de modifier le code de l'application avec confiance sans introduire de r√©gression, on peut alors mettre en place une d√©marche d'automatisation. Cela va permettre √† l'√©quipe de d√©veloppement d'obtenir un retour rapide lors de chaque d√©ploiement, avec un lancement automatis√© des tests ainsi qu'un d√©ploiement automatique de l'application sur un environnement de recette interne par exemple.

L'un des objectifs de l'int√©gration et du d√©ploiement continu est de banaliser le d√©ploiement afin de r√©duire la peur des d√©veloppeurs vis-√†-vis de la mise en production. Plus le code est d√©ploy√© souvent, plus les d√©veloppeurs seront sereins quant √† leur travail puisqu'ils pourront obtenir des retours rapide et √™tre pr√©venu au plus vite lors d'incident afin de les corriger avant qu'il n'atteigne la production.

\subsubsection{Gestion de version, de branches et des op√©rations}

Il est tout d'abord essentiel de d√©finir une strat√©gie de gestion de version et de branches du code, afin de s'assurer une bonne mise en place de l'automatisation. De plus, il est important de r√©fl√©chir aux actions qui devront √™tre entrepris dans chaque cas. 

En effet, avec l'automatisation du processus d'int√©gration, de livraison et de d√©ploiement, il est n√©cessaire d'adopter en amont des \emph{conventions} afin de couvrir les diff√©rents cas qui pourraient survenir. Les actions entreprises ne seront pas les m√™mes pour couvrir une op√©ration de qualim√©trie du code que pour g√©rer le d√©ploiement d'un \gls{hotfix}.

\paragraph{Gestion de branches}

La gestion de branches est importante √† bien d√©finir puisqu'elle va rythmer les flux de travail de d√©veloppement des √©quipes. Il n'est donc pas envisageable de changer les habitudes de travail des √©quipes toutes les 3 semaines sous pr√©texte que ce flux de travail sera plus adapt√© avec les outils d'int√©gration ou de d√©ploiement continu.

On peut alors d√©finir des conventions de nommage des branches. Par exemple, on peut utilises une branche \emph{master} qui repr√©sente l'√©tat de la version de production et une autre branche \emph{develop} dite de d√©veloppement sur laquelle les \emph{Dev} travaillent. Une branche de \gls{hotfix} peut √™tre conventionnellement nomm√©e \emph{hotfix\_NUMERO\_INCIDENT} par exemple pour g√©rer les incidents de production. Une fois ces conventions mises en place, il sera alors plus facile de d√©terminer diff√©rents comportement dans les outils d'int√©gration et de d√©ploiement continu, tel que Jenkins √† titre d'exemple.

\emph{Au niveau des branches, de nombreuses conventions existent, ci-dessous est pr√©sent√© un exemple.}

Le feature branching, aussi connu sous le nom de \frquote{git flow} consiste √† organiser son processus de d√©veloppement sous forme de branche, en faisant correspondre √† chaque fonctionnalit√© une branche. On conserve le principe de branche \emph{master} et \emph{develop} pr√©sent√©e dans le paragraphe pr√©c√©dent, mais √† chaque fois que l'on souhaite d√©velopper une fonctionnalit√©, on cr√©√© une branche en se basant depuis \emph{develop}, ce qui permet de laisser les branches de d√©veloppement et de production relativement saine. Une fois le d√©veloppement de la fonctionnalit√© termin√©e, il suffit alors de \emph{merger}\footnote{fusionner le code original et le code d√©velopp√© sur la branche de fonctionnalit√©} les deux branches pour r√©cup√©rer le travail.

\newImage{0.2}{feature-branching.png}{Illustration du feature branching - \url{https://www.atlassian.com}}{feature-branching}

Le feature flipping n'est pas √† proprement parler un flux de travail puisqu'il peut tr√®s bien s'accorder sur un flux de travail tel que le feature branching ou sur une branche simple mais il est int√©ressant de le mentionner. Il consiste √† envelopper chaque fonctionnalit√© avec un param√®tre de configuration, de sorte √† pouvoir activer et d√©sactiver rapidement des fonctionnalit√©s. Cela peut permettre de tester des nouvelles fonctionnalit√©s progressivement vis-√†-vis des utilisateurs ou d'effectuer du \gls{test-a-b} afin de d√©terminer quelle solution est la plus pl√©biscit√©e par les utilisateurs. 

Un exemple de feature flipping peut √™tre le d√©ploiement de la nouvelle interface de Gandi\footnote{\url{http://gandi.net/}} qui a progressivement propos√© sa nouvelle interface\footnote{\url{https://news.gandi.net/fr/tag/gandiv5/}} √† ses utilisateurs via un bouton leur permettant de tester la nouvelle interface, tout en leur autorisant un retour √† l'ancienne s'ils le souhaitaient. 

\paragraph{Gestion de version}

Une fois que l'on a d√©termin√© la fa√ßon dont le code source sera organis√©, il est n√©cessaire de d√©terminer la fa√ßon dont les versions du logiciel seront effectu√©es. En effet, il faut √™tre en mesure de pouvoir dire quelle version est d√©ploy√©e sur quel environnement. Il est rare de disposer seulement d'une production, on dispose √† minima pour un projet d'un environnement de recette et d'une pr√©-production, et souvent d'un contexte de staging pour pouvoir valider les modifications √† diff√©rentes √©tapes et √©viter de se retrouver avec un bug en production. Ainsi, il n'est pas rare d'avoir une version A en production, avec une version B en pr√©-production et une version C en recette client.

La version doit √™tre immuable, c'est √† dire qu'il ne doit pas √™tre possible de d√©clarer deux fois la m√™me version. Une fois d√©clar√©e, la version doit √™tre tagu√©e dans le \gls{SCM} afin d'en garder une trace et de la retrouver si besoin. Concernant le format de la version, il doit pouvoir √™tre automatiquement incr√©ment√© par les outils d'int√©gration et de d√©ploiement continus. On recommande g√©n√©ralement alors soit un format de version via la date (\emph{2019-06-17.1} pour la premi√®re version du 17/06/2019 par exemple) ou un format standardis√©, tel que le Semanting Versionning\footnote{\url{https://semver.org/}} dont le but est d'indiquer via le num√©ro de version les compatibilit√©s entre version. Ainsi, une version 1.0.0 et une 2.0.0 peuvent entrainer des non compatibilit√©s ascendante ou descendante. N√©anmoins, une 1.0.0 et une 1.1.0 indique l'ajout de fonctionnalit√©s n'entrainant pas de non-compatibilit√©s et la diff√©rence entre une 1.0.0 et une 1.0.1 indique l'ajout d'un correctif mineur.

\paragraph{Gestion des op√©rations}

Une fois la fa√ßon dont le code est g√©r√© par le \gls{SCM} et la fa√ßon dont on nomme nos versions, on peut se poser la question sur les diff√©rentes actions √† effectuer. On va en effet vouloir effectuer des actions rapide suite √† une modification du code pour pouvoir valider que ce code est fonctionnel (en lan√ßant les tests unitaire par exemple) mais on ne va pas vouloir forc√©ment produire imm√©diatement la qualim√©trie du code, qui peut prendre du temps √† √™tre g√©n√©r√©e et donc faire attendre les √©quipes de d√©veloppements qui attendent un retour rapide. De m√™me, selon les clients, on va vouloir d√©ployer automatiquement un projet s'il passe les tests d'int√©gration et les tests syst√®me, mais certains projets anciens n'ayant pas forc√©ment assez de tests ne peuvent peut-√™tre pas se permettre un d√©ploiement imm√©diat et il faudra alors demander une validation manuelle.

Les op√©rations sont √† pr√©voir pour tous les cas pouvant intervenir, qu'il s'agissent de d√©ploiement d'une nouvelle version, d'un \gls{hotfix} ou de la construction de d√©pendances internes √©tant r√©utilis√©s par d'autres applications (voir annexe \ref{annexe:commons-modules}).

On peut consulter sur l'annexe \ref{annexe:release-naq} le diagramme des op√©rations pour le d√©ploiement d'une nouvelle version d'un site de la \naq{} qui passera par 4 environnements, un de staging, suivi d'une recette effectu√©e par le client, puis d'une pr√©-production et enfin de l'environnement de production. On constate que le serveur d'int√©gration continu (ici Jenkins) est au c≈ìur des op√©rations effectu√©es et sert de chef d'orchestre pour interagir avec les autres outils et environnements. 

Une autre notion que l'on peut voir sur ce sch√©ma est la notion de promotion d'artifact. Un artifact repr√©sente un fichier (dans ce cas, une archive contenant le site √† d√©ployer) stock√© sur un \gls{artifactory}. Ce fichier va, au cours du \emph{pipeline}\footnote{Flux de travail}, √™tre valid√© selon qu'il a ou non √©t√© correctement d√©ploy√© sur un environnement donn√©. On va alors promouvoir ce fichier selon des statuts d√©fini arbitrairement afin de situer l'√©volution du fichier. Les statuts d√©finis dans ce pipeline sont les suivants : \frquote{staging}, \frquote{RC}\footnote{Release Candidate, correspondant √† l'environnement de recette client} et \frquote{production}\footnote{dans l'annexe, production est implicite}. On consid√®re alors que si le package atteint l'environnement de pr√©-production, il peut directement √™tre promu en tant que version d√©finitive.

Il y a √©galement un dernier aspect important concernant la gestion des op√©rations lorsque l'on souhaite mettre en place une d√©marche \devops : Il s'agit de ne pas viser trop grand d√®s le d√©but. On peut en effet tout automatiser (mont√©e de version des d√©pendances automatique, d√©ploiement et provisionnement d'environnement de tests automatiquement\ldots) mais en fonction du besoin et du budget client, tout ne sera pas possible. Il vaut peut-√™tre mieux commencer par ne faire que de l'int√©gration continue, sans livraison ou d√©ploiement continue, que vouloir construire une chaine d'industrialisation tellement complexe qu'elle ne sera utilis√©e par personne et aura cout√©e plus cher que le d√©veloppement du projet. La matrice en annexe \ref{annexe:devops-matrice} pr√©sente bien cela, avec divers niveaux, repr√©sentant diff√©rentes √©tapes vers la mise en place d'une d√©marche \devops.

\subsubsection{Choix des outils}

Une fois que l'on sait comment g√©rer ses branches, ses versions et que l'on sait les diff√©rentes op√©rations √† effectuer pour les diff√©rents cas d'usages, il convient de s√©lectionner les bon outils afin de mener √† bien le projet.

Un \gls{SCM} est √©videmment obligatoire pour pouvoir effectuer une int√©gration continue des changements du code, taguer les diff√©rentes versions ou encore permettre de s√©parer le travail en cours avec diff√©rentes branches. Plusieurs solutions existent, certaines propri√©taires, d'autres open-source ou auto-h√©bergeables. Parmi les plus populaires, on peut citer \github\footnote{\url{https://github.com}}, Gitea\footnote{\url{https://gitea.io}}, solution auto-h√©bergeable et √©conome en terme de ressources ou encore Gitlab\footnote{\url{https://gitlab.com}} qui est utilis√© dans le cas des projets de la \naq, auto-h√©berg√© au sein de \onepoint.

Chaque projet va souvent d√©pendre de d√©pendances. Dans le cas d'un projet \gls{PHP}, on va souvent retrouver des d√©pendances via composer, qui sont des d√©pendances externes. Mais on peut √©galement d√©pendre de d√©pendances internes, qui peuvent √™tre des composants r√©utilis√©s en interne au sein de plusieurs projets. Il faut alors pouvoir g√©rer ses d√©pendances. S'il est possible de d√©ployer ses d√©pendances internes sur Packagist\footnote{Gestionnaire de d√©pendances \gls{PHP} - \url{https://packagist.org/}}, il se peut que l'on souhaite garder la main sur ses d√©pendances, ou ne pas les rendre publique, et que l'on souhaite donc les garder sur un gestionnaires de paquets priv√©s. Dans le cas de la \naq, c'est l'\gls{artifactory} de Jfrog\footnote{Gestionnaire de fichier binaire - \url{https://jfrog.com/artifactory/}} qui est utilis√© afin de g√©rer ses d√©pendances. Concr√®tement, cela consiste √† ajouter un repository\footnote{d√©p√¥t} au fichier de d√©finition des d√©pendances (dans le cas de \gls{PHP}, il s'agit d'un fichier appel√© \frquote{composer.json}).

%\begin{listing}[H]
%	\begin{minted}{json}
%	{
%	"type": "composer",
%	"url": "https://ARTIFACTORY/api/composer/nouvelle-aquitaine",
%	"vendor-alias": "nouvelle-aquitaine"
%	}
%	\end{minted}
%	\caption{D√©finition d'un d√©p√¥t composer externe dans un fichier %\frquote{composer.json}}
%	\label{code:composer-setup}
%\end{listing}

Il est ensuite n√©cessaire, pour pouvoir effectuer de l'int√©gration continue, de disposer d'un serveur\ldots{} D'int√©gration continue. De nombreux outils existent, chacun se d√©marquant avec ses propres fonctionnalit√©s. Les plus connus sont TravisCI\footnote{\url{http://travis-ci.org/}} qui est souvent utilis√© lors de projets √©tant versionn√© sous \github, TeamCity\footnote{\url{https://www.jetbrains.com/teamcity/}} qui apr√®s ses \gls{IDE}, propose √©galement son propre outil d'int√©gration continue. Finalement, le leader reste Jenkins\footnote{\url{http://jenkins.io/}}. Tous permettent de r√©aliser de l'int√©gration continue, mais proposent souvent plus, tel que la livraison ou encore le d√©ploiement continu, le tout selon les besoins \& le budget du client.

\subsubsection{Int√©gration continue}

% AKA build continu
% S√©parer en deux jobs : un apr√®s push + un par jour qui fait la qualim√©trie.

\todo{Int√©gration continue}

Le but de l'int√©gration continue est d'int√©grer les changements des \emph{Dev} et de les tester, √† chaque nouvelle modification du code. Pour cela, on utilise un logiciel s'ex√©cutant sur un serveur, connect√© au gestionnaire de sources contenant le code. D√®s qu'une modification de code est pouss√©e sur le gestionnaire de source, un \gls{webhook} est envoy√© √† l'outil d'int√©gration continue (par exemple Jenkins \cite{jenkins-guide}) qui va alors d√©rouler un certains nombre d'√©tapes d√©finies (installation des d√©pendances, ex√©cutions des tests\ldots) pour v√©rifier que l'application est conforme aux demandes client. Ces retours doivent √™tre rapide afin que les d√©veloppeurs puissent s'assurer qu'il n'y a pas d'erreurs bloquante dans leur code.

On peut alors d√©couper l'int√©gration continue en deux √©tapes. La premi√®re serait \textbf{le build continu}, qui consiste √† fournir un retour rapide aux d√©veloppeur. Son temps d'ex√©cution doit √™tre de l'ordre de quelques minutes maximum, c'est pourquoi on se contente souvent de lancer seulement les \gls{TU}. On retrouve l'illustration de ce flux de travail dans l'annexe \ref{annexe:build-continu}.

Une autre √©tape importante de l'int√©gration est la \textbf{qualim√©trie}. Il s'agit d'un job qui va √™tre ex√©cut√© une fois par jour, en g√©n√©ral la nuit\footnote{lorsque l'activit√© sur le projet est faible} et qui va construire le projet en r√©cup√©rant les derni√®res sources disponibles sur la branche de d√©veloppement, ex√©cuter les tests unitaire, des tests de qualim√©trie, tel que des outils de d√©tection de code copier coller qui pourrait √™tre plus difficile √† maintenir\footnote{En \gls{PHP}, il existe PHPCPD qui r√©pond √† ce besoin - \url{https://github.com/sebastianbergmann/phpcpd}} et on va ex√©cuter les tests d'int√©gration, qui peuvent n√©cessiter le provisionnement d'une base de donn√©es et √™tre plus long √† ex√©cuter que les \gls{TU}. Une fois tous ces tests effectu√©s, on va g√©n√©rer un rapport et le mettre √† disposition des √©quipes de d√©veloppement qui pourront le consulter le lendemain √† leur retour et prendre en compte les remarques du rapport.

% M√©triques pour attester d√©roulement OK => test OK/KO, temps traitement. 

\subsubsection{Livraison continue}

\todo{Livraison continue}

Une √©tape suivant l'int√©gration continue est la livraison continue. Cette derni√®re consiste √† construire l'application, ses d√©pendances et √† continuellement construire un binaire (souvent une archive zip ou tar.gz) qui va permettre le d√©ploiement de l'application.

Livre du Build des package + test continu d√®s leur validation. Syst√®me de promotion environnement manuel.

M√©triques pour attester d√©roulement OK => Taille paquet, temps traitement. 

Permet d√©ploiement via interaction humaine.

\textit{Exemple : parler de NAQ Automatisation de la cr√©ation de la base de donn√©es et de la restauration des donn√©es}

\subsubsection{D√©ploiement continu}

\todo{D√©ploiement continu}

deploiement de packages continu d√®s leur cr√©ation et validation. Syst√®me de promotion auto.

M√©triques pour attester d√©roulement OK => Uptime, temps d√©ploiement, ratio rollback suite √† d√©ploiement foir√©\ldots

scalabilit√©, r√©silience. provisionner de nouveaux serveurs rapidement avec Ansible par exemple. Inconv√©nient : n√©cessite une architecture d√©coupl√©e, si on vient a faire un changemnt (ex: rajouter un serveur redis) mais qu'on doit attendre 2 semaines pour valider ce changement, on pert int√©r√™t

\subsubsection{Gestion de l'infrastructure}

\todo{Gestion de l'infrastructure}

\gls{IaC} => permet de d√©coupler architecture ? % https://dev.to/klauenboesch/why-use-infrastructure-as-a-code-3793

% https://aws.amazon.com/fr/cloudformation/ ----------- https://www.terraform.io/

\subsubsection{Monitoring}

\todo{Monitoring}

% https://prometheus.io/

Le reporting de bug automatique (sentry.io)

Monitoring : monit pour monitorer l'√©tat d'application ? (perso)

ELK, traitement logs, grafana\ldots

\subsection{Et la s√©curit√© dans tout √ßa ?}

Un projet automatis√© de A √† Z peut √™tre test√© int√©gralement, si la s√©curit√© autour de l'infrastructure d'int√©gration et de d√©ploiement n'est pas s√©curis√©e, cela revient √† avoir une s√©curit√© digne d'une porte ouverte.

En effet, si l'on vient √† d√©ployer de fa√ßon automatique, il va falloir que les outils d√©ployant et testant automatiquement l'application ait acc√®s aux donn√©es de l'application, donn√©es qui peuvent parfois contenir des tokens, des cl√©s d'\gls{API}\ldots Il faut alors r√©fl√©chir √† la fa√ßon de s√©curiser l'infrastructure. 

Il faut tout d'abord restreindre les acc√®s aux diff√©rents outils d'automatisation. Pour cela, on peut se servir d'un pare feu, qui va filtrer les connexions entrantes sur les diff√©rents serveurs. On peut √©galement mettre en place une \gls{DMZ}, qui permet ainsi de s√©parer le r√©seau interne de celui externe, connect√© √† Internet et qui contient les applications ayant besoin d'√™tre accessible via l'ext√©rieur. En plus de cela, on peut √©galement restreindre les acc√®s aux diff√©rentes applications via la mise en place d'un \gls{VPN}, qui permet l'acc√®s aux applications via une connexion s√©curis√©e, comme si l'on √©tait pr√©sent sur site et √©vite ainsi d'avoir √† exposer les applications sur Internet. Mais toutes ces mesures sont valable pour tout type d'application, automatis√©e ou non. 

On peut (\emph{et l'on doit}) aussi se r√©f√©rer √† la documentation des outils d'automatisation utilis√©s. Par exemple, la documentation de Jenkins\footnote{\url{https://jenkins.io/doc/}} ainsi que le livre num√©rique \citetitle{jenkins-guide} \cite[chapitre 7, S√©curiser Jenkins]{jenkins-guide} d√©crivent les fa√ßons de s√©curiser l'outil et √©viter ainsi que le serveur d'int√©gration ne serve de vecteur d'attaque pour compromettre l'application (\emph{ou pire, l'entreprise enti√®re, √©tant donn√© qu'un syst√®me d'int√©gration continu est souvent utilis√© pour plusieurs projets}). Une des premi√®res mesures est de restreindre les acc√®s utilisateurs, en appliquant le principe de moindre privil√®ge. Cela signifie donner uniquement les droits strictement n√©cessaire. Si un utilisateur a simplement besoin de consulter les rapports, il n'y a pas d'int√©r√™t de lui donner les droits pour pouvoir √©diter la configuration de ces derniers.

Concernant les interactions entre le serveur d'int√©gration continue, le gestionnaire de version et les diff√©rents serveurs, il peut √™tre int√©ressant de cr√©er un compte de service (\emph{compte syst√®me, n'√©tant reli√© √† aucun utilisateur et disposant des droits minimaux pour l'ex√©cution de la t√¢che pour lequel il est utilis√©}) avec des acc√®s par cl√© \gls{SSH} utilis√©s pour les d√©ploiements. L'utilisation d'une cl√© \gls{SSH} plut√¥t qu'un mot de passe est n√©cessaire puisque la demande de mot de passe se fait de fa√ßon interactive (et requiert donc une intervention utilisateur)\footnote{M√™me s'il est possible de contourner ce fonctionnement, par exemple avec sshpass, il est recommand√© d'utiliser des cl√©s \gls{SSH}}. De m√™me, l'acc√®s aux serveurs doit √™tre limit√© et surtout contr√¥l√©. Il faut ainsi pr√©f√©rer des comptes nominatif, m√™me si leur cr√©ation peut s'av√©rer plus fastidieuse plut√¥t qu'un seul compte administrateur partag√© entre les membres de l'√©quipe. Ainsi, si un compte vient √™tre compromis, il est plus facile de r√©voquer ses acc√®s plut√¥t que de bloquer l'acc√®s √† tous les membres de l'√©quipe.

Un autre aspect √† prendre en compte, selon la confidentialit√© requise par les projets, est l'endroit ou le code source du projet va transiter. Si par exemple, un prestataire ne dispose pas de son propre serveur d'int√©gration continue mais poss√®de une offre chez un autre prestataire (TravisCI par exemple), il faut √™tre prudent, puisque le code sera alors √† un moment transmis en dehors du r√©seau de l'entreprise. Selon les projets, il peut √™tre n√©cessaire d'auto-h√©berger des solutions en interne afin de garder une maitrise totale de la chaine d'industrialisation.

Finalement, il ne faut pas oublier la v√©rification de la s√©curit√© de l'application elle-m√™me. En effet, une application n√©cessite souvent des d√©pendances externes, r√©alis√©es par d'autres personnes. Comment s'assurer que ces d√©pendances sont √† jour et fiable ? 

On peut ainsi utiliser les outils de gestion de d√©pendances afin de s'assurer que les d√©pendances sont √† jour. Cela requiert n√©anmoins une action manuelle de la part du d√©veloppeur. Des outils existent donc afin de surveiller les mises √† jour des d√©pendances, tel que Depfu\footnote{\url{https://depfu.com/}} ou encore DependABot\footnote{\url{https://dependabot.com/}} et permettent de s'int√©grer directement la chaine d'int√©gration continue en proposant des modifications sur une branche d√©di√©e, bas√©e sur la branche de travail principale du d√©p√¥t du gestionnaire de version, ce qui permet de tester ces modifications avant de les int√©grer dans l'application.

%\begin{listing}[H]
%	\begin{minted}{bash}
%	#!/bin/bash
%	# Liste les d√©pendances non mises √† jour
%	npm outdated # Javascript
%	composer outdated # PHP
%	bundle outdated # Ruby
%	\end{minted}
%	\caption{Exemple de v√©rification des d√©pendances non mises √† jour}
%\end{listing}

\todo[color=cyan]{S√©curit√©, 1-2 page }

OWASP ZAAP

bastion qui peut permettre de couper l'acc√®s √† l'infra.