\subsection{Gestion de projet}

\epigraph{\frquote{Avoir 300 personnes dans une cuisine pour faire un ≈ìuf au plat ne permettra pas de servir le plat 300 fois plus vite}}{Analogie de la \frquote{Loi de Brooks\footnote{\url{https://fr.wikipedia.org/wiki/Loi_de_Brooks}}}}

\subsubsection{Partie financi√®re}
L'automatisation d'un projet ne peut s'effectuer un en jour. De m√™me que la citation ci-dessus a du sens, la migration d'un projet existant vers une automatisation totale ne peut s'effectuer en un jour, m√™me en mobilisant de grands moyens. Il est donc n√©cessaire de pr√©parer et planifier une conduite du changement qui permettra d'accompagner tous les acteurs du projet afin que la transition s'effectue dans les meilleures conditions possibles. Cela passe d'abord par une r√©flexion sur la conduite √† adopter et les changements √† apporter. 

Prenons pour exemple un projet fonctionnel depuis maintenant plusieurs mois. Le projet a d√©j√† √©t√© livr√© (avec plus ou moins de difficult√©) quelques fois en production. Comment convaincre que l'automatisation va apporter du bien √† ce projet‚ÄØ? Qui est-il n√©cessaire de convaincre‚ÄØ?

Tout d'abord, il faut convaincre les personnes responsables financi√®rement du projet. En effet, il est possible d'avoir un projet automatis√© de A √† Z, si ce processus d'automatisation vient √† co√ªter 3 fois le prix total vendu au client, aucun responsable ne vous donnera son accord. Il va √©galement falloir convaincre les personnes responsables du projet (chef de projet, directeur de projet...) qu'il y a un int√©r√™t √† effectuer cela. En effet, sans garantie que ce processus pourra amener quelque chose de positif, peu laisseront une opportunit√© d'essayer d'automatiser un projet.

Il faut ainsi pr√©parer son argumentaire, avec les bienfaits que cela pourra obtenir sur les \gls{KPI} et sur la vie du projet √† moyen/long terme.

\begin{description}
	\setlength\itemsep{0em}
	\item [La dur√©e de de d√©ploiement] peut √™tre r√©duite pour permettre de se concentrer sur d'autres probl√©matiques. De plus, si les temps de d√©ploiement sont r√©duits, cela signifie que les temps d'interruption de service pourront √™tre r√©duit lors des livraisons.
	\item [Erreur de d√©ploiement] Si les d√©ploiements sont automatis√©s, les risques d'incidents lors des d√©ploiements, souvent d√ª √† des erreurs humaines, seront alors r√©duit.
	\item [Rentabilit√© financi√®re] Prenons une t√¢che qui co√ªte \numprint{3000}‚Ç¨ √† r√©aliser toutes les 3 semaines. Son co√ªt est donc assez √©lev√©. Le fait d'automatiser cette t√¢che permettra d'√©conomiser de l'argent sur la dur√©e. Si le fait d'automatiser cette t√¢che co√ªte par exemple, \numprint{10000}‚Ç¨, un gain sera per√ßu d√®s la 12\up{√®me} semaine.\label{ref-rentabilite-finance}
	\item [Part de march√©] Si les d√©ploiements sont plus fiables et rapides, que la rentabilit√© financi√®re du projet est √©galement florissante alors il sera possible de concentrer les efforts sur des fonctionnalit√©s √† fortes valeurs ajout√©es qui permettront ainsi de se d√©marquer de la concurrence et d'augmenter les parts de march√© √† moyen/long terme. C'est ce que les √©conomistes appellent la comp√©titivit√© hors-prix.
	\item [\Gls{timetomarket}] Dans un environnement tr√®s concurrentiel, il est essentiel de pouvoir intervenir rapidement. R√©duire la dur√©e entre la naissance d'une id√©e/besoin et sa mise en production est important, sous peine de voir des concurrents prendre des parts de march√©. L'automatisation peut alors permettre de d√©ployer rapidement et avec confiance les d√©veloppements r√©alis√©s.
	\item [Reprise d'activit√©] Il s'agit ici de d√©montrer que le produit parfait n'existe pas. Il arrivera que l'application soit hors ligne √† cause d'un incident ou qu'une mise √† jour entraine une interruption de service. En revanche, si l'on ne peut √©viter l'incident √† un moment donn√©, il est capital de pouvoir restaurer l'application rapidement. Disposer d'un \gls{PCA} ou d'un \gls{PRA} int√©grant une automatisation de la reprise d'activit√© est un atout non n√©gligeable qui permettra une reprise de l'activit√© au plus vite. On peut alors passer d'une interruption de plusieurs heures √† une se comptant en minutes.\label{ref-pra}
\end{description}

\subsubsection{Organiser le flux de travail}
Il est √©galement n√©cessaire de planifier au mieux les dur√©es des travaux √† accomplir afin d'√©viter des d√©passements dans les d√©lais annonc√©s. Cela implique donc de r√©fl√©chir au temps n√©cessaire √† investir et aux diff√©rents jalons qui valideront la bonne mise en place de l'automatisation. 

Pour pouvoir mettre en place une d√©marche d'automatisation sur un projet, il est n√©cessaire que ce dernier soit assez mature pour pouvoir s'y adapter. Ainsi, comme l'indique \citetitle{phoenixProject} \cite{phoenixProject}, avant de se lancer dans une d√©marche d'automatisation (\emph{ou plus globalement, pour pouvoir g√©rer correctement un projet}), la premi√®re √©tape est de savoir g√©rer le flux de travail.

Le flux de travail, ce sont les diff√©rentes t√¢ches qui sont √† r√©aliser sur le projet. Ces derni√®res sont souvent des stories (\emph{dans le cas d'une m√©thodologie agile}), d√©finies conjointement avec le client et correspondent ainsi √† ce qui a √©t√© d√©fini dans le cahier des charges. L'inconv√©nient est que ce flux de travail est fragile. Il peut rapidement d√©river et se retrouver perturb√©, surchargeant ainsi les √©quipes. Le principal ennemi de flux de travail est le travail non pr√©vu (\emph{unplanned work}). Ce sont toutes les petites t√¢ches non pr√©vues, qui prennent 10 √† 15 minutes, qui ne sont suivies nulle part et qui mises bout √† bout peuvent faire perdre plusieurs jours de travail et √©puiser les √©quipes, qui ne voit jamais le travail diminuer.

Quelles sont donc les solutions pour g√©rer ce travail non pr√©vu ? L'objectif est ici de faire en ce sorte que ce travail non pr√©vu ne soit plus ex√©cut√© directement sans passer par une phase minimale de planification. Pour cela, il est possible de mettre en place des kanbans. Qu'est-ce qu'un Kanban ? Il s'agit d'une m√©thode de repr√©sentation des t√¢ches qui permet de visualiser l'avanc√©e du projet en temps r√©el (\emph{ou du moins, √† chaque fois que le tableau est mis √† jour}). On peut ainsi limiter le travail non pr√©vu, en l'ajoutant √† une cat√©gorie d√©di√©e, le \emph{backlog}, qui correspond √† la pile de t√¢che √† r√©aliser. Une fois ces t√¢ches estim√©es, d√©coup√©es et discut√©es avec le client, elles peuvent √™tre consid√©r√©es comme pr√™tes √† √™tre commenc√©es. On parle alors de \emph{D√©finition Of Ready}. De m√™me, pour d√©terminer qu'une t√¢che a √©t√© termin√©e par l'√©quipe de d√©veloppement et donc pr√™te √† √™tre livr√©e, on parle de \emph{Definition Of Done}, ce qui correspond √† une liste de points, √©tabli par l'√©quipe en interne. Ces points correspondent √† des √©l√©ments √† v√©rifier et √† cocher pour indiquer si une t√¢che est vraiment termin√©e ou non. On peut y retrouver par exemple l'√©criture de tests ou encore le fait qu'une autre personne ait relu le code, le fait que la documentation ait √©t√© mise √† jour\ldots

On peut ensuite suivre l'√©volution des t√¢ches dans leur diff√©rentes √©tapes, du d√©veloppement √† leur livraison, en passant par les tests. Ainsi, le travail non pr√©vu ne peut plus d√©ranger un sprint en cours puisqu'il est possible de d√©finir des limites, en disant par exemple que seules les t√¢ches √©tant pr√™tes seront travaill√©es dans ce sprint et que les autres devront attendre le prochain sprint pour pouvoir √™tre trait√©es. N√©anmoins, il s'agit de faire attention √† un point en mettant en place un kanban. En effet, si l'on met simplement en place un kanban et que l'on continue de traiter les t√¢ches comme elles l'√©taient pr√©c√©demment, on s'expose au risque de voir le travail en cours, ou \emph{WIP\footnote{Work In Progress}} s'accumuler. Cela risque donc de ralentir les √©quipes voir de les d√©motiver. De plus, si tout le travail est en WIP, il n'y a aucune fa√ßon de savoir depuis combien de temps un t√¢che est d√©but√©e, ce qui fait que certaines t√¢ches peuvent tr√®s bien rester en WIP pendant des jours voir des semaines. La solution √† ce probl√®me tient dans le fait de limiter le travail en cours. En effet, en limitant le travail en cours, on s'assure que les t√¢ches ne resteront pas √©ternellement en attente. De plus, si le travail en cours est restreint, il sera de meilleur qualit√©, puisque moins dispers√© et engendrera donc moins de bug‚ÄØ!

\subsubsection{Livrer plus rapidement de la valeur m√©tier}

L'un des objectifs de l'automatisation est √©galement de faciliter le passage d'un syst√®me o√π l'on met plusieurs mois avant de livrer une grosse fonctionnalit√© √† un autre o√π de multiples petites fonctionnalit√©s sont livr√©es plus r√©guli√®rement. Attendre plusieurs mois pour livrer une fonctionnalit√© peut en effet avoir des effets ind√©sirables.

\begin{itemize}
	\setlength\itemsep{0em}
	\item Dans une √©poque hyper-concurrentielle o√π l'on veut tout, toujours plus vite, certains besoins sont √©ph√©m√®res ou n√©cessitent un \gls{timetomarket} faible pour se d√©marquer de la concurrence. Si la fonctionnalit√© est livr√©e une fois le besoin pass√©, cette derni√®re n'a plus de sens. Cela vaut aussi si l'on vient √† livrer un produit une fois que tous les concurrents sont d√©j√† positionn√©s dessus. Il vaut mieux livrer petit √† petit des parties du besoin pour pouvoir l'am√©liorer continuellement.
	\item Une fonctionnalit√© qui met longtemps √† √™tre livr√©e induira un stress au niveau des √©quipes, qui auront sur leurs √©paules la responsabilit√© de livrer \emph{la fonctionnalit√© parfaite}, plut√¥t que livrer plusieurs petites fonctionnalit√©s.
	\item Le risque d'√©chec est beaucoup plus important en livrant une fonctionnalit√© plut√¥t que plusieurs petites, surtout si cette derni√®re inclut des changements d'architecture (\emph{Structure de la base de donn√©es, ajout de nouveaux composants...})
	\item Plus on attend longtemps pour livrer une fonctionnalit√©, plus on prend le risque de se retrouver dans le cas d'un \emph{effet tunnel} ou la compr√©hension de ce qui √©tait √† faire s'est retrouv√©e au fur et √† mesure du temps par √™tre l'oppos√© de ce qui √©tait demand√©. Dans cette position, le client et le chef de projet communique souvent peu, l'√©quipe de d√©veloppement travaille en g√©n√©ral sans avertir de ses avanc√©es,\ldots Seule la date limite permet de voir ce qui a √©t√© r√©alis√© et il s'agit plus souvent d'un √©chec que d'une r√©ussite.
\end{itemize}

Cette volont√© de vouloir livrer plus petit mais plus r√©guli√®rement s'inscrit dans \emph{l'am√©lioration continue}. Au d√©but, la fonctionnalit√© ne sera peut-√™tre pas parfaite, mais elle sera continuellement am√©lior√©e jusqu'√† correspondre au besoin voulu. On peut voir cela illustr√© sur la figure \ref{fig:devopsObjective} avec l'illustration de la collaboration entre les d√©veloppeurs (qui apportent de la valeur ajout√©e au client) et les administrateurs syst√®mes (qui mettent √† disposition l'application au client). On constate tout de suite qu'il vaut mieux livrer plusieurs petites fonctionnalit√©s (et donc avoir une forte collaboration entre les deux √©quipes) apportant chacune une valeur ajout√©e certes plus faible plut√¥t que le premier sch√©ma o√π si la livraison √©choue, le client se retrouve sans application.

\newImage[H]{1}{devops-objective.jpg}{Mise en place de l'am√©lioration continue entre \emph{Dev} et \emph{Ops} - \url{https://itrevolution.com}}{devopsObjective}

N√©anmoins, il convient de v√©rifier que ce syst√®me est int√©gr√© et accept√© par l'√©quipe, sous peine de voir un rejet de cette m√©thodologie \devops{} et d'entrainer des conflits internes au sein des √©quipes. Cela peut √™tre le cas avec certaines personnes r√©fractaires au changement, par exemple des d√©veloppeurs √¢g√©s, proches de le retraite, qui n'ont peut-√™tre pas envie de se former √† nouveau et s'adapter √† de nouvelles m√©thodes de travail et qui tenteront de garder leurs habitudes. Cela peut √©galement provenir de personnalit√©s avec un fort caract√®re qui pensent que leur m√©thode est plus efficace que les autres ou encore de bien d'autres cas. De mani√®re g√©n√©rale, les personnes ne souhaitent pas sortir de leur zone de confort. Pour permettre ce changement, il va falloir exposer les diff√©rents avantages aux √©quipes et leur montrer les int√©r√™ts qu'ils ont √† s'essayer √† cette m√©thode pour peut-√™tre finir par l'adopter de leur plein gr√©. 

Afin de faire int√©grer ce syst√®me par une √©quipe, il faut tout d'abord trouver des personnes qui sont ouvertes au changement, des \glsplural{earlyadopter} qui ont envie de voir cette am√©lioration se mettre en place. Dans l'id√©al, ces personnes seront √©galement des personnes influentes vis-√†-vis des autres afin de permettre une meilleure int√©gration du changement par le suite. Il faut ensuite convaincre une majorit√© de personne et les amener vers ce changement. L'id√©e est de construire une base plus importante de personnes souhaitant voir cette √©volution se mettre en place afin de ne laisser que les personnes r√©fractaires au changement √† g√©rer par la suite, quitte √† les mettre devant le fait accompli une fois une majorit√© de personnes convaincues. On peut voir cette mise en place de la culture \devops{} d√©taill√©e dans \citetitle{devOpsHandbook} \cite[p.58-59]{devOpsHandbook}.

\subsubsection{Retours et apprentissage continu}

L'un des premiers avantages si l'on met en place une d√©marche d'automatisation est une meilleure communication entre les d√©veloppeurs, √©galement appel√©s \emph{Dev}, et les administrateurs syst√®mes, appel√©s \emph{Ops}. Si l'on met en place une d√©marche d'automatisation, un besoin de m√©trique va √™tre n√©cessaire. Ces m√©triques, semblables aux \gls{KPI} pr√©c√©demment d√©taill√©s, permettront de savoir par exemple le temps de d√©ploiement de l'application, les derniers bugs remont√©s, les suivis de performance afin de d√©terminer si une requ√™te \gls{SQL} est trop lente ou non\ldots{} Ces m√©triques, conjointement d√©finies par les d√©veloppeurs et les administrateurs syst√®mes vont permettre d'obtenir des retours rapides sur l'√©tat de l'application et ainsi de pouvoir am√©liorer le produit plus facilement, en corrigeant les bugs au plus t√¥t. C'est la base de la \emph{Second Way}, ou deuxi√®me √©tape, comme expliqu√© dans \citetitle{phoenixProject} \cite[p.405-410]{phoenixProject}.

Un autre point √† prendre en compte lors d'une d√©marche d'automatisation est l'apprentissage continu. Comme nous l'avons vu dans la partie pr√©c√©dente, \etsy{} a mis en place un outil de post-mortem (p.\pageref{post-mortem}) qui permet de savoir les erreurs rencontr√©es dans le pass√© et de permettre qu'elles ne se reproduisent plus. Cette notion constitue la \emph{Third Way} mais ne se limite pas seulement aux erreurs rencontr√©es. Avec le temps obtenu par l'automatisation, il est ainsi possible de s'am√©liorer sur d'autres points : partager les connaissances de chacun pour faire progresser l'√©quipe et les personnes la constituant, documenter et am√©liorer l'int√©gration de nouvelles personnes dans les √©quipes ou les environnements de travail\ldots{} L'√©quipe sera alors plus performante et pourra ainsi d√©livrer de meilleurs produits.

\subsection{Environnement de d√©veloppement}

L'environnement de d√©veloppement est le premier environnement o√π sont d√©velopp√©es les diff√©rentes fonctionnalit√©s du projet. Ce cadre de travail doit pouvoir √™tre install√© rapidement afin de se concentrer sur le d√©veloppement de fonctionnalit√©s et non sur l'installation de l'environnement de travail.

\subsubsection{Arriv√©e sur le projet}

Plusieurs personnes sont potentiellement amen√©es √† travailler sur le projet. Il est donc important de documenter l'installation et les pr√©-requis afin de pouvoir commencer √† travailler. Il n'est malheureusement pas rare de voir des projets o√π la documentation du projet est faible, voir inexistante.

L'id√©al pour un d√©veloppeur qui vient d'arriver sur un projet serait de disposer d'un environnement pr√™t √† l'emploi, qui puisse se lancer en quelques commandes (installation des d√©pendances et provisionnement de l'environnement). Des outils de conteneurisation tel que Docker\footnote{\url{https://www.docker.com/}} permettent ainsi d'avoir des environnements isol√©s et reproductibles quelque soit l'environnement du d√©veloppeur. De plus, avec Docker, l'architecture du projet est repr√©sent√© sous forme textuelle et donc int√©grable dans le \gls{SCM}, ce qui permet de savoir les √©volutions sur l'architecture du projet facilement. De plus, un projet qui peut s'installer rapidement signifie qu'un d√©veloppeur peut √™tre efficient plus rapidement sur son projet. Il peut ainsi apporter ses comp√©tences sur de r√©elles probl√©matiques plut√¥t qu'√™tre bloqu√© pendant de longues heures √† chercher comment installer ledit projet.

Afin de permettre un d√©marrage rapide, il est √©galement commun de mettre des alias sur les commandes les plus utilis√©es lors des d√©veloppements. Par exemple, si une commande permettant d'effacer le cache de l'application est longue √† taper, on la raccourcira en quelque chose tel que \frquote{make clear} par exemple. Pour cela, plusieurs solutions sont disponibles : les scripts \gls{PHP} dans le cas d'un projet \gls{PHP} ou encore l'utilisation des Makefile, permettant de construire les logiciels et leur d√©pendances et d'y effectuer des t√¢ches diverses, d√©finies dans un fichier. Il est √©galement possible d'√©crire des scripts shell\footnote{L'interpr√©teur de commande disponible sous Linux, pas la compagnie p√©troli√®re \emoji{üòä}}, permettant d'effectuer des t√¢ches plus complexes\footnote{Comme faire le caf√© ? \emoji{üòä} - \url{https://github.com/NARKOZ/hacker-scripts}}

De plus, il est souvent n√©cessaire d'avoir des configurations sp√©cifiques sur les environnements de d√©veloppements. En effet, dans un contexte de d√©veloppement, on va vouloir obtenir les erreurs imm√©diatement, dans un terminal par exemple, alors que dans un environnement de production, ces derni√®res seront dans un fichier de log. De plus, on va pouvoir vouloir tracer le temps que prend chaque requ√™te vers une base de donn√©es ou encore disposer d'outils permettant de mettre des points d'arr√™ts dans le code afin de pouvoir d√©bugger lors des phases de d√©veloppements. Il faut donc des moyens d'activer ses outils simplement. Cela peut passer par des scripts ou encore des images Docker d√©di√©es au d√©veloppement, bas√©e sur celle de production. Le but est d'obtenir un environnement le plus proche possible de la production tout en ayant la possibilit√© d'ajouter des outils de d√©veloppements additionnels.

\subsubsection{Build local}

Le build local correspond √† la premi√®re boucle de retour du d√©veloppeur. C'est dans cet environnement qu'il obtient des retours rapide, que cela soit sur ses tests unitaire, ses √©ventuelles fautes de frappe, erreur de syntaxe\ldots. L'objectif de ce build local est de d√©tecter les erreurs au plus t√¥t, pour √©viter qu'elles ne soient potentiellement oubli√©es et non d√©tect√©es par les autres √©tapes du flux de travail et provoque un bug en production alors qu'il aurait pu √™tre √©vit√© simplement. Plusieurs solutions peuvent alors √™tre mises en place pour am√©liorer ce build local.

\paragraph{L'utilisation d'un IDE}

L'objectif de l'\gls{IDE} est de fournir un support de travail au d√©veloppeur et de lui rep√©rer de fa√ßons automatique des erreurs d'inattention. Il convient alors de se familiariser avec un \gls{IDE} afin de tirer le maximum de ce dernier. Parmi les fonctionnalit√©s communes d'un bon \gls{IDE}, on retrouve :

\begin{itemize}
	\setlength\itemsep{-0.5em}
	\item D√©tection des erreurs de syntaxe
	\item Ajout automatique des imports dans un fichier
	\item Lancement automatique des tests unitaire √† la sauvegarde/modification d'un fichier
	\item Auto-compl√©tion automatique permettant de conna√Ætre le nom des m√©thodes et fonction √† la saisie
	\item Indenter le code selon des conventions d√©finies
	\item Affichage des erreurs simple √† d√©tecter (tel qu'un code non atteignable car apr√®s un retour de fonction par exemple)
\end{itemize}

Les \gls{IDE} disposent souvent de plugins qui permettent d'√©tendre leurs fonctionnalit√©s pour am√©liorer le quotidien du d√©veloppeur. Par exemple, certains plugins vont permettre de g√©rer l'affichage de l'√©tat de la base de donn√©es, s'interfacer avec l'√©tat des outils d'int√©grations continue distants (via les \gls{API} de ces derniers) afin de savoir si les tests d'int√©grations sont pass√©s ou non\ldots

\paragraph{Les hooks du SCM} Git, \gls{SCM} utilis√© de fa√ßon majoritaire dans les d√©veloppements dispose d'un m√©canisme permettant d'√©tendre ses fonctionnalit√©s : les hooks. Ces hooks, tel que d√©crits dans la documentation (\citetitle{git-hook} \cite[chapitre 8.3]{git-hook}) permettent de lancer des scripts √† certaines √©tapes, tel qu'avant un commit, avant de pousser le code sur le serveur, apr√®s r√©ception des modifications du serveur\ldots{} Cela permet souvent de v√©rifier que les tests unitaires passent, qu'il n'y a pas d'erreur de syntaxe ou encore que le linter\footnote{analyse de code statique permettant de d√©tecter les erreurs communes, et d'instaurer une syntaxe (r√®gles d'espacement, nommage des variables\ldots) commune} ne g√©n√®re pas d'erreur.

\paragraph{Le pair programming (programmation en bin√¥me)}

Le pair programming consiste √† d√©velopper √† deux d√©veloppeurs sur le m√™me poste de travail. Bien qu'au premier abord, cela puisse sembler √™tre une perte de temps et d'argent (puisqu'il n'y a finalement qu'une seule personne qui tape sur le clavier), cette m√©thode permet de d√©tecter des erreurs plus t√¥t, puisqu'il y a 2 paires d'yeux qui peuvent relever les erreurs au lieu d'une seule. Souvent, il peut arriver un d√©veloppeur seul d'√™tre \frquote{la t√™te dans le guidon}, c'est-√†-dire qu'il est tellement absorb√© dans son code et peut donc oublier certains cas, certaines r√®gles m√©tiers\ldots{} Le fait de travailler en bin√¥me permet ainsi de d√©celer ces erreurs plus t√¥t et d'assurer une meilleure qualit√© de code. Les deux d√©veloppeurs √©changent rapidement leurs r√¥les afin de travailler de fa√ßon efficace et de passer d'observateur √† d√©veloppeur. 

\subsection{L'importance des tests} \label{importance-test}

Les tests ont un r√¥le crucial dans une d√©marche d'automatisation. En effet, lorsque l'on automatise quelque chose, il est essentiel de s'assurer que le comportement de l'application est valide puisque l'on va par la suite d√©ployer automatiquement cette application en production. Selon le \gls{CFTL}, il existe 4 types de tests et chacun dispose de quatre objectifs formant ainsi une matrice repr√©sent√©e dans le tableau \ref{tab:matrice-test}.

\begin{table}[H]
	\centering
	\begin{adjustbox}{width=0.95\textwidth,center=\textwidth} 
		\begin{tabular}{|l|l|l|l|l|}
			\hline
			\diagbox{type de test}{valide} & Fonctionnement unitaire & R√®gle m√©tier & D√©veloppement & Interaction \\ \hline
			Test de composant     & X                       & X            & X              &             \\ \hline
			Test d'int√©gration    &                         & X            & X              & X           \\ \hline
			Test Syst√®me          &                         & X            &               & X           \\ \hline
			Test d'acceptation    &                         & X            &               &             \\ \hline
		\end{tabular}
	\end{adjustbox}
	\caption{Matrice de tests selon leur type et leur objectif}
	\label{tab:matrice-test}
\end{table}

\subsubsection{Le test de composant}\label{test-composant}

Son objectif est que le composant test√© soit totalement isol√© afin de se concentrer uniquement sur le \emph{fonctionnement unitaire} de ce dernier, sans d√©pendre d'autre composant. On peut alors tester tous les cas, du cas dit \frquote{g√©n√©ral}, qui repr√©sente souvent 80\% des cas, jusqu'aux \frquote{cas limites}, cas apparaissant plus rarement mais pouvant entrainer un comportement non souhait√© de l'application. Cela permet de v√©rifier que le code √©crit par le d√©veloppeur lors de la phase de \emph{d√©veloppement} est bien valide. Ainsi, un test de composant peut valider des \emph{r√®gles m√©tier} et ainsi √©galement correspondre √† un test d'acceptation\footnote{d√©tails sur les tests d'acceptation dans la sous partie \frquote{\nameref{test-acceptation}} (p. \pageref{test-acceptation})}.

Un exemple commun de test de composant est par exemple le test d'une m√©thode de calcul d'une calculette. On dispose d'une m√©thode \frquote{calculer} disposant de 3 param√®tres, 2 \frquote{op√©randes} num√©riques et un \frquote{op√©rateur}. Un cas g√©n√©ral serait alors de tester que \frquote{3+2} retourne bien \frquote{5} et un cas limite serait de tester que \frquote{5/0} l√®ve bien une exception, puisqu'il s'agit d'une op√©ration ill√©gale. Dans le cas de \gls{PHP}, un exemple de \gls{framework} de test unitaire est PHPUnit\footnote{\url{https://phpunit.de/}}. Le principal avantage de ce type de test est sa rapidit√© : ne n√©cessitant aucune interaction avec des composants externes (ou bien ces composants disposent d'un \gls{mock}), l'ex√©cution des tests est tr√®s rapide.

\subsubsection{Le test d'int√©gration}

Une fois chaque composant test√© unitairement, il convient de v√©rifier que ces composants sont capable d'\emph{interagir} entre eux. En effet, dans la sous-partie pr√©c√©dente, il √©tait indiqu√© que les composants √©taient isol√©s les uns des autres. N√©anmoins, dans de nombreux cas, il est n√©cessaire que des composants interagissent entre eux. On va alors utiliser un \gls{mock} afin de simuler le comportement d'un composant, afin de tester l'autre.

Un exemple serait une \gls{API} qui communiquerait avec une base de donn√©es afin de retourner les r√©sultats. Lorsque l'on teste l'\gls{API} unitairement, on ne souhaite pas d√©pendre de la base de donn√©es. On va donc simuler les r√©ponses normalement fournies par la base de donn√©es et envoyer ces donn√©es √† l'\gls{API} qui pourra alors √™tre test√©e de fa√ßon isol√©e.

Cependant, si l'on teste toute notre application de cette fa√ßon, il est impossible d'attester le bon fonctionnement de nos composants entre eux. La version de la base de donn√©es pourrait en effet √™tre incompatible avec le code actuellement utilis√© par l'\gls{API}. Si aucun test d'int√©gration n'est effectu√©, la confiance dans l'application sera bas√©e sur le \gls{mock} de la base de donn√©es et on risque alors de se retrouver dans le cas de la figure \ref{fig:no-integration-test}, avec des composants isol√©s fonctionnant tr√®s bien individuellement mais incapable de s'ex√©cuter ensemble. Cela s'illustre avec la figure \ref{fig:no-integration-test}. Dans ce cas, les tiroirs s'ouvrent tr√®s bien individuellement mais lorsqu'ils sont assembl√©s, il n'est pas possible d'ouvrir les deux tiroirs en m√™me temps, puisque le premier bloque l'ouverture du second.

\newImage{0.4}{no-integration-tests.png}{Exemple de tests unitaire sans tests d'int√©gration.}{no-integration-test}

Les tests d'int√©gration vont donc garantir que chaque composant, d√©ploy√© dans l'environnement d'ex√©cution de l'application, est capable de communiquer de fa√ßon correcte avec ses d√©pendances.

\subsubsection{Le test syst√®me}

Les tests syst√®mes permettent de tester le comportement de l'application sans forc√©ment avoir connaissance du code. Cela permet ainsi de v√©rifier que l'application effectue bien ce qui est indiqu√© dans les sp√©cifications demand√©es et que les diff√©rents composants interagissent bien entre eux. Ces tests sont √©galement appel√©s \frquote{tests boite noire}. De plus, les tests syst√®mes permettent de v√©rifier que les composants interagissent correctement entre eux, au niveau global de l'application (\emph{au niveau syst√®me}) et non en mettant un composant dans l'application et en regardant son comportement avec les autres composants, comme c'est le cas avec le test d'int√©gration.

Ce sont √©galement les tests qui sont les plus hauts niveaux, puisqu'ils s'ex√©cutent avec toute l'application et ses d√©pendances / composants. On peut par exemple citer les tests End to End qui sont des tests syst√®mes qui permettent de tester le comportement d'une application de bout en bout en d√©crivant les actions r√©alis√©es sur cette derni√®re (cliquer sur un bouton, r√©duire la fen√™tre) et les r√©sultats attendus.

Le \gls{framework} \gls{angularjs} , par exemple, permet de r√©aliser des tests End to End avec Protractor\footnote{\url{https://www.protractortest.org/}}. Cela va ainsi √©muler un navigateur dans lequel il va √™tre possible de d√©crire les comportements utilisateurs. 

Un autre exemple de test syst√®me serait un test de charge, r√©alis√© sur un environnement similaire √† la production, durant lequel on ne va pas tester la conformit√© de l'application mais sa capacit√© √† supporter un certain trafic. Dans le cas d'une application web, cela consiste √† simuler des centaines ou milliers de connexions simultan√©es sur le site afin de v√©rifier sa capacit√© √† r√©pondre convenablement. √âvidemment, tester ceci sur un environnement avec une configuration diff√©rente de la production n'a que peu de sens, puisque le serveur de test sera alors sous-dimensionn√©, sur-dimensionn√© ou disposera d'une gestion du cache diff√©rente par exemple mais dans tous les cas, les r√©sultats seront fauss√©s.

L'avantage de ces tests syst√®mes est qu'il s'agit des tests les plus complets, puisqu'ils permettent de tester le produit fini. L'inconv√©nient est qu'ils sont plus longs √† ex√©cuter.

\subsubsection{Le test d'acceptation}\label{test-acceptation}

Souvent r√©alis√© par le client, il va consister, au travers d'une campagne de test g√©n√©ralement manuelle, √† v√©rifier que les \emph{r√®gles m√©tiers} sont bien respect√©es. Le client peut n√©anmoins d√©cider de d√©l√©guer ce test √† une √©quipe qualit√©, ou √† un prestataire externe.

Il est n√©anmoins possible que certains tests d'acceptation soient valid√©s en amont, comme l'exemple de la calculatrice donn√©e dans la partie \frquote{\nameref{test-composant}} (p. \pageref{test-composant}) qui va valider la \emph{r√®gle m√©tier} (effectuer une op√©ration) tout en validant le bon fonctionnement du code et ses cas limites.

\subsubsection{Les tests par mutation}\label{ref-mutation}

L'objectif des tests par mutation est de v√©rifier la pertinence des cas de tests. En effet, une couverture de 100\% de code via des tests ne garantit pas que 100\% du code soit r√©ellement test√©. Voici le d√©roulement des tests par mutation : 

\begin{enumerate}
	\setlength\itemsep{0em}
	\item On part d'une classe m√©tier sur laquelle on souhaite v√©rifier la pertinence de nos tests.
	\item On d√©termine les op√©rations possibles √† effectuer : changement de condition, changement d'op√©rateurs (< ; > ; <= ; >= ; != ; == ; \ldots), \ldots
	\item On g√©n√®re alors des \frquote{mutants}\footnote{√âvidemment, des outils existent afin de g√©n√©rer ces mutants automatiquement. En \gls{PHP}, \url{https://github.com/infection/infection} est utilis√© pour g√©n√©rer et pr√©senter les r√©sultats de ces tests par mutation} qui vont correspondre √† tous les changements possibles selon les crit√®res d√©finis √† l'√©tape pr√©c√©dente. C'est une √©tape qui peut √™tre tr√®s longue √† g√©n√©rer selon le nombre de crit√®res s√©lectionn√©s dans l'√©tape pr√©c√©dente. Une fois cela effectu√©, on va donc disposer de plusieurs classes \frquote{mutantes}.
	\item On lance alors notre test contre la classe m√©tier originale, et on s'assure que les tests soient valides.
	\item On lance ensuite les tests sur chacune des classes \frquote{mutantes}.
\end{enumerate}

Logiquement, le code ayant chang√©, des erreurs dans les tests devraient alors apparaitre dans un ou plusieurs cas. Si tous les tests sont valides, cela veut dire que le test ignore un ou plusieurs comportements de la classe et qu'il faut revoir la pertinence des tests.

\subsubsection{Choisir les type de tests √† prioriser}

Chaque application √©tant diff√©rente, tous les types de tests ne sont pas adapt√©s √† toutes les applications. Il faut donc d√©terminer les tests √† prioriser, selon le type de produit que l'on livre.

Ainsi, dans le cas d'une application m√©tier complexe, telle que les banques, assurances ou les cas d'utilisations sont nombreux et n√©cessitent des algorithmes potentiellement compliqu√©s, il peut √™tre int√©ressant de concentrer ses efforts sur des tests d'acceptation via des tests unitaire pour valider les besoins m√©tiers, du fait de leur criticit√©.

Si l'on vient √† travailler avec des \gls{cms} ou que l'on interagit avec des services qui ne sont pas de notre ressort, il y a des risques non n√©gligeables de se retrouver dans des cas o√π les mises √† jour de ces services risquent d'entrainer des r√©gressions. Il faut alors concentrer ses efforts sur les tests d'int√©gration pour s'assurer que le code d√©velopp√© puisse correctement s'ex√©cuter avec les librairies tierces.

\subsection{Int√©gration, d√©ploiement et livraison continue}

Une fois que les tests permettent de modifier le code de l'application avec confiance sans introduire de r√©gression, on peut alors mettre en place une d√©marche d'automatisation. Cela va permettre √† l'√©quipe de d√©veloppement d'obtenir un retour rapide lors de chaque d√©ploiement, avec un lancement automatis√© des tests ainsi qu'un d√©ploiement automatique de l'application sur un environnement de test interne par exemple.

L'un des objectifs de l'int√©gration et du d√©ploiement continu est de banaliser le d√©ploiement afin de r√©duire la peur des d√©veloppeurs vis-√†-vis de la mise en production. Plus le code est d√©ploy√© souvent, plus les d√©veloppeurs seront sereins quant √† leur travail puisqu'ils pourront obtenir des retours rapide et √™tre pr√©venus au plus vite lors d'incident afin de les corriger avant qu'il n'atteigne la production.

\subsubsection{Gestion de version, de branches et des op√©rations}

Il est tout d'abord essentiel de d√©finir une strat√©gie de gestion de version et de branches du code, afin de s'assurer une bonne mise en place de l'automatisation. De plus, il est important de r√©fl√©chir aux actions qui devront √™tre entrepris dans chaque cas. 

En effet, avec l'automatisation du processus d'int√©gration, de livraison et de d√©ploiement, il est n√©cessaire d'adopter en amont des \emph{conventions} afin de couvrir les diff√©rents cas qui pourraient survenir. Les actions entreprises ne seront pas les m√™mes pour couvrir une op√©ration de qualim√©trie du code que pour g√©rer le d√©ploiement d'un \gls{hotfix}.

\paragraph{Gestion de branches}

La gestion de branches est importante √† bien d√©finir puisqu'elle va rythmer les flux de travail de d√©veloppement des √©quipes. Il n'est donc pas envisageable de changer les habitudes de travail des √©quipes toutes les 3 semaines sous pr√©texte que ce flux de travail sera plus adapt√© avec les outils d'int√©gration ou de d√©ploiement continu.

On peut alors d√©finir des conventions de nommage des branches. Par exemple, on peut utiliser une branche \emph{master} qui repr√©sente l'√©tat de la version de production et une autre branche \emph{develop} dite de d√©veloppement sur laquelle les \emph{Dev} travaillent. Une branche de \gls{hotfix} peut √™tre conventionnellement nomm√©e \emph{hotfix\_NUMERO\_INCIDENT} par exemple pour g√©rer les incidents de production. Une fois ces conventions mises en place, il sera alors plus facile de d√©terminer diff√©rents comportements dans les outils d'int√©gration et de d√©ploiement continu, tel que Jenkins √† titre d'exemple.

\emph{Au niveau des branches, de nombreuses conventions existent, ci-dessous est pr√©sent√© un exemple.}

Le feature branching, aussi connu sous le nom de \frquote{git flow} consiste √† organiser son processus de d√©veloppement sous forme de branche, en faisant correspondre √† chaque fonctionnalit√© une branche. On conserve le principe de branche \emph{master} et \emph{develop} pr√©sent√©e dans le paragraphe pr√©c√©dent, mais √† chaque fois que l'on souhaite d√©velopper une fonctionnalit√©, on cr√©e une branche en se basant depuis \emph{develop}, ce qui permet de laisser les branches de d√©veloppement et de production relativement saine. Une fois le d√©veloppement de la fonctionnalit√© termin√©e, il suffit alors de \emph{merger}\footnote{fusionner le code original et le code d√©velopp√© sur la branche de fonctionnalit√©} les deux branches pour r√©cup√©rer le travail.

\newImage{0.2}{feature-branching.png}{Illustration du feature branching - \url{https://www.atlassian.com}}{feature-branching}

Le feature flipping n'est pas √† proprement parler un flux de travail puisqu'il peut tr√®s bien s'accorder sur un flux de travail tel que le feature branching ou sur une branche simple mais il est int√©ressant de le mentionner. Il consiste √† envelopper chaque fonctionnalit√© avec un param√®tre de configuration, de sorte √† pouvoir activer et d√©sactiver rapidement des fonctionnalit√©s. Cela peut permettre de tester des nouvelles fonctionnalit√©s progressivement vis-√†-vis des utilisateurs ou d'effectuer du \gls{test-a-b} afin de d√©terminer quelle solution est la plus pl√©biscit√©e par les utilisateurs. 

Un exemple de feature flipping peut √™tre le d√©ploiement de la nouvelle interface de Gandi\footnote{\url{http://gandi.net/}} qui a progressivement propos√© sa nouvelle interface\footnote{\url{https://news.gandi.net/fr/tag/gandiv5/}} √† ses utilisateurs via un bouton leur permettant de tester la nouvelle interface, tout en leur autorisant un retour √† l'ancienne s'ils le souhaitaient. 

\paragraph{Gestion de version}\label{gestion-de-version}

Une fois que l'on a d√©termin√© la fa√ßon dont le code source sera organis√©, il est n√©cessaire de d√©terminer la fa√ßon dont les versions du logiciel seront effectu√©es. En effet, il faut √™tre en mesure de pouvoir dire quelle version est d√©ploy√©e sur quel environnement. Il est rare de disposer seulement d'une production, on dispose √† minima pour un projet d'un environnement de recette et d'une pr√©-production, et souvent d'un contexte de staging pour pouvoir valider les modifications √† diff√©rentes √©tapes et √©viter de se retrouver avec un bug en production. Ainsi, il n'est pas rare d'avoir une version A en production, avec une version B en pr√©-production et une version C en recette client.

La version doit √™tre immuable, c'est-√†-dire qu'il ne doit pas √™tre possible de d√©clarer deux fois la m√™me version. Une fois d√©clar√©e, la version doit √™tre tagu√©e dans le \gls{SCM} afin d'en garder une trace et de la retrouver si besoin. Concernant le format de la version, il doit pouvoir √™tre automatiquement incr√©ment√© par les outils d'int√©gration et de d√©ploiement continus. On recommande g√©n√©ralement d'utiliser un format standardis√©, tel que le Semanting Versionning\footnote{\url{https://semver.org/}} dont le but est d'indiquer via le num√©ro de version les compatibilit√©s entre version. Ainsi, une version 1.0.0 et une 2.0.0 peuvent entrainer des non-compatibilit√©s ascendantes ou descendantes. N√©anmoins, une 1.0.0 et une 1.1.0 indique l'ajout de fonctionnalit√©s n'entrainant pas de non-compatibilit√©s et la diff√©rence entre une 1.0.0 et une 1.0.1 indique l'ajout d'un correctif mineur.

\paragraph{Gestion des op√©rations}

Une fois la fa√ßon dont le code est g√©r√© par le \gls{SCM} et la fa√ßon dont on nomme nos versions, on peut se poser la question sur les diff√©rentes actions √† effectuer. Suite √† une modification du code, on va en effet vouloir effectuer des actions rapides pour pouvoir valider que ce dernier est fonctionnel (en lan√ßant les tests unitaire par exemple) mais on ne va pas vouloir forc√©ment produire imm√©diatement la qualim√©trie du code, qui peut prendre du temps √† √™tre g√©n√©r√©e et donc faire attendre les √©quipes de d√©veloppements qui attendent un retour rapide. De m√™me, selon les clients, on va vouloir d√©ployer automatiquement un projet s'il passe les tests d'int√©gration et les tests syst√®mes, mais certains projets anciens n'ayant pas forc√©ment assez de tests ne peuvent peut-√™tre pas se permettre un d√©ploiement imm√©diat et il faudra alors demander une validation manuelle.

Les op√©rations sont √† pr√©voir pour tous les cas pouvant intervenir, qu'il s'agisse de d√©ploiement d'une nouvelle version, d'un \gls{hotfix} ou de la construction de d√©pendances internes √©tant r√©utilis√©s par d'autres applications. On peut consulter sur l'annexe \ref{annexe:release-naq} le diagramme des op√©rations pour le d√©ploiement d'une nouvelle version d'un site de la \naq{} qui passera par 4 environnements, un de staging, suivi d'une recette effectu√©e par le client, puis d'une pr√©-production et enfin de l'environnement de production. On constate que le serveur d'int√©gration continu (ici Jenkins) est au c≈ìur des op√©rations effectu√©es et sert de chef d'orchestre pour interagir avec les autres outils et environnements.

Une autre notion que l'on peut voir sur ce sch√©ma est la notion de promotion d'artifact. Un artifact repr√©sente un fichier (dans ce cas, une archive contenant le site √† d√©ployer) stock√© sur un \gls{artifactory}. Ce fichier va, au cours du \emph{pipeline}\footnote{Flux de travail}, √™tre valid√© selon qu'il a ou non √©t√© correctement d√©ploy√© sur un environnement donn√©. On va alors promouvoir ce fichier selon des statuts pr√©d√©finis arbitrairement afin de situer l'√©volution du fichier. Les statuts d√©finis dans ce pipeline sont les suivants : \frquote{staging}, \frquote{RC}\footnote{Release Candidate, correspondant √† l'environnement de recette client} et \frquote{production}. On consid√®re alors que si le package atteint l'environnement de pr√©-production, il peut directement √™tre promu en tant que version d√©finitive.

Il y a √©galement un dernier aspect important concernant la gestion des op√©rations lorsque l'on souhaite mettre en place une d√©marche \devops : Il s'agit de ne pas viser trop grand d√®s le d√©but. On peut en effet tout automatiser (mont√©e de version des d√©pendances automatique, d√©ploiement et provisionnement d'environnement de tests automatiquement\ldots) mais en fonction du besoin et du budget client, tout ne sera pas possible. Il vaut peut-√™tre mieux commencer par ne faire que de l'int√©gration continue, sans livraison ou d√©ploiement continue, que vouloir construire une chaine d'industrialisation tellement complexe qu'elle ne sera utilis√©e par personne et aura cout√©e plus cher que le d√©veloppement du projet. La matrice en annexe \ref{annexe:devops-matrice} pr√©sente bien cela, avec divers niveaux, repr√©sentant diff√©rentes √©tapes vers la mise en place d'une d√©marche \devops.

\subsubsection{Choix des outils}

Une fois que l'on sait comment g√©rer ses branches, ses versions et que l'on connait les diff√©rentes op√©rations √† effectuer pour les diff√©rents cas d'usages, il convient de s√©lectionner les bons outils afin de mener √† bien le projet.

Un \gls{SCM} est √©videmment obligatoire pour pouvoir effectuer une int√©gration continue des changements du code, taguer les diff√©rentes versions ou encore permettre de s√©parer le travail en cours avec diff√©rentes branches. Plusieurs solutions existent, certaines propri√©taires, d'autres open-source ou auto-h√©bergeables. Parmi les plus populaires, on peut citer \github\footnote{\url{https://github.com}}, Gitea\footnote{\url{https://gitea.io}}, solution auto-h√©bergeable et √©conome en termes de ressources ou encore Gitlab\footnote{\url{https://gitlab.com}} qui est utilis√© dans le cas des projets de la \naq, auto-h√©berg√© au sein de \onepoint.

Chaque projet va souvent d√©pendre de d√©pendances. Dans le cas d'un projet \gls{PHP}, on va souvent retrouver des d√©pendances via composer, qui sont des d√©pendances externes. Mais on peut √©galement d√©pendre de d√©pendances internes, qui peuvent √™tre des composants r√©utilis√©s en interne au sein de plusieurs projets. Il faut alors pouvoir g√©rer ses d√©pendances. S'il est possible de d√©ployer ses d√©pendances internes sur Packagist\footnote{Gestionnaire de d√©pendances \gls{PHP} - \url{https://packagist.org/}}, il se peut que l'on souhaite garder la main sur ses d√©pendances, ou ne pas les rendre publiques, et que l'on souhaite donc les garder sur un gestionnaire de paquets priv√©s. Dans le cas de la \naq, c'est l'\gls{artifactory} de Jfrog\footnote{Gestionnaire de fichier binaire - \url{https://jfrog.com/artifactory/}} qui est utilis√© afin de g√©rer ses d√©pendances. Concr√®tement, cela consiste √† ajouter un repository\footnote{d√©p√¥t} au fichier de d√©finition des d√©pendances (dans le cas de \gls{PHP}, il s'agit d'un fichier appel√© \frquote{composer.json}).

Il est ensuite n√©cessaire, pour pouvoir effectuer de l'int√©gration continue, de disposer d'un serveur\ldots{} D'int√©gration continue. De nombreux outils existent, chacun se d√©marquant avec ses propres fonctionnalit√©s. Les plus connus sont TravisCI\footnote{\url{http://travis-ci.org/}} qui est souvent utilis√© lors de projets √©tant versionn√© sous \github, TeamCity\footnote{\url{https://www.jetbrains.com/teamcity/}} qui apr√®s ses \gls{IDE}, propose √©galement son propre outil d'int√©gration continue. Finalement, le leader reste Jenkins\footnote{\url{http://jenkins.io/}}. Tous permettent de r√©aliser de l'int√©gration continue, mais proposent souvent plus, tel que la livraison ou encore le d√©ploiement continu, le tout selon les besoins \& le budget du client.

\subsubsection{Int√©gration continue}

Le but de l'int√©gration continue est d'int√©grer les changements des \emph{Dev} et de les tester, √† chaque nouvelle modification du code. Pour cela, on utilise un logiciel s'ex√©cutant sur un serveur, connect√© au \gls{SCM} contenant le code. D√®s qu'une modification de code est pouss√©e sur le \gls{SCM}, un \gls{webhook} est envoy√© √† l'outil d'int√©gration continue (par exemple Jenkins \cite{jenkins-guide}) qui va alors d√©rouler un certain nombre d'√©tapes d√©finies (installation des d√©pendances, ex√©cutions des tests\ldots) pour v√©rifier que l'application est conforme aux demandes clients. Ces retours doivent √™tre rapides afin que les d√©veloppeurs puissent s'assurer qu'il n'y a pas d'erreurs bloquantes dans leur code.

On peut alors d√©couper l'int√©gration continue en deux √©tapes. La premi√®re serait \textbf{le build continu}, qui consiste √† fournir un retour rapide aux d√©veloppeurs. Son temps d'ex√©cution doit √™tre de l'ordre de quelques minutes maximum, c'est pourquoi on se contente souvent de lancer seulement les tests unitaire. On retrouve l'illustration de ce flux de travail dans l'annexe \ref{annexe:build-continu}. Il est √©galement possible d'effectuer une analyse statique du code afin de d√©tecter certaines erreurs qui ne seraient normalement d√©tect√©es qu'√† l'ex√©cution du code\footnote{cela s'applique aux langages interpr√©t√©s, tel que \gls{PHP}}. En \gls{PHP}, il est possible d'utiliser PHPStan\footnote{PHP Static Analysis Tool - \url{https://github.com/phpstan/phpstan}} afin de s'assurer que le code soit syntaxiquement correct, comme on peut le voir en exemple dans l'annexe \ref{annexe:php-error}.

Une autre √©tape importante de l'int√©gration continue est la phase de \textbf{qualim√©trie}. Il s'agit d'un job\footnote{ensemble d'√©tapes qui vont √™tre ex√©cut√©es sur le serveur d'int√©gration continue} qui va √™tre ex√©cut√© une fois par jour, en g√©n√©ral la nuit\footnote{lorsque l'activit√© sur le projet est faible}. Le projet va alors √™tre construit en r√©cup√©rant les derni√®res sources disponibles sur la branche de d√©veloppement. On va ensuite ex√©cuter les tests unitaire, des tests de qualim√©trie, tel que des outils de d√©tection de code  copier-coller\footnote{En \gls{PHP}, il existe PHPCPD qui r√©pond √† ce besoin - \url{https://github.com/sebastianbergmann/phpcpd}} qui pourraient indiquer des \glsplural{code-smell} et on va ex√©cuter les tests d'int√©gration, qui peuvent n√©cessiter le provisionnement d'une base de donn√©es et √™tre plus long √† ex√©cuter que les tests unitaire. Une fois tous ces tests effectu√©s, on va g√©n√©rer un rapport et le mettre √† disposition des √©quipes de d√©veloppement qui pourront le consulter le lendemain √† leur retour et prendre en compte les remarques du rapport. 

Dans le cas des projets sur la \naq{}, il a √©t√© mis en place un autre test qui intervient lors de la phase de qualim√©trie et qui permet d'attester que les mises √† jour se d√©roulent correctement. Chaque nuit, la derni√®re version de la branche de d√©veloppement est r√©cup√©r√©e avec la derni√®re sauvegarde de la base de donn√©es de pr√©-production. On restaure alors cette base de donn√©es sur une base de donn√©es temporaire et on vient jouer toutes les mises √† jour de sch√©ma, ainsi que les diff√©rents hooks de mise √† jour\footnote{Dans le \gls{cms} \gls{drupal}, les \frquote{hooks update} permettent de d√©finir des mises √† jour √† jouer afin de mettre √† jour des sch√©mas o√π effectuer des t√¢ches de migration lors d'une livraison}. Cela permet de tester dans un environnement isol√© que les mises √† jour de sch√©ma ne viennent pas entrainer de r√©gression ou erreur. Cela ne garantit n√©anmoins pas qu'elles sont fonctionnelles mais permet de s'assurer de leur bonne ex√©cution.

Bien que l'int√©gration continue ne permette pas de d√©ployer une application, elle permet de mesurer la qualit√© de cette derni√®re et par cons√©quent, la potentielle difficult√© (ou facilit√©) √† livrer et d√©ployer l'application. Les m√©triques collect√©es peuvent √™tre nombreuses et indiquer des axes d'am√©liorations divers.

\begin{itemize}
	\setlength\itemsep{0em}
	\item Le nombre de tests OK / KO peut permettre d'indiquer la stabilit√© de l'application.
	\item Si l'installation des d√©pendances √©choue, on est tout de suite au courant que le commit ayant chang√© les d√©pendances a entrain√© cette r√©gression.
	\item Un score √©lev√© de copier-coller au sein d'une application peut indiquer des \gls{code-smell} potentiels, voir une erreur dans la structure de l'application.
	\item De m√™me, l'analyse de code statique permet de relever des erreurs et avertissements sur lesquels il est bon d'avoir des points d'attention, m√™me s'il peut parfois s'agit de faux positifs.
\end{itemize}

\subsubsection{Livraison continue}

Si l'int√©gration continue permet d'attester de la qualit√© du code et d√©tecte des potentielles r√©gressions avant leur livraison, la livraison continue permet quant √† elle d'obtenir un livrable (souvent un binaire, tel qu'une archive) qui va permettre de d√©ployer √† tout moment l'application. 

On va alors construire p√©riodiquement l'application au sein d'un job d√©di√©, qui va r√©cup√©rer les derni√®res sources du code de la branche de d√©veloppement, installer les d√©pendances, effectuer les divers tests d√©crits pr√©c√©demment et construire le livrable contenant ainsi toutes les d√©pendances de l'application. On pourrait tr√®s penser qu'il n'est pas n√©cessaire d'inclure les d√©pendances de l'application dans le livrable et que l'on pourrait se contenter de les installer lors du d√©ploiement. Bien que cela soit possible et parfois pratiqu√©, c'est une pratique d√©conseill√©e puisqu'elle implique de faire confiance √† un √©l√©ment qui ne peut √™tre consid√©r√© comme digne de confiance : Internet. 

Comment garantir que la version demand√©e de cette d√©pendance externe va bien √™tre r√©cup√©r√©e ? Qu'il ne va pas y avoir d'interruptions r√©seaux ? Que le proxy ou pare-feu va autoriser la connexion pour t√©l√©charger des d√©pendances externes ? Toutes ces questions ne peuvent √™tre garanties. Quant bien m√™me les t√©l√©chargements des d√©pendances seraient r√©ussis, cela n√©cessiterait de v√©rifier les \gls{checksum} de chaque d√©pendance pour √™tre s√ªr qu'il n'y a pas eu de corruption de donn√©es. Cela augmenterait le temps de d√©ploiement et ajouterait de potentielles erreurs, entrainant des retours en arri√®res forc√©s qui aurait pu √™tre √©vit√©s s'ils avaient √©t√© d√©tect√©s plus t√¥t. Le fait de construire le livrable avec ses d√©pendances avant sa livraison garantit que les d√©pendances r√©solues √† un instant T sont fiables (v√©rification de \gls{checksum}) et garantit que le livrable est installable, normalement, sans erreurs. Une fois le livrable construit, on va g√©n√©rer un \gls{checksum} de l'archive g√©n√©r√©e et c'est ce \gls{checksum} qui sera v√©rifi√© lors du d√©ploiement. Si lors du d√©ploiement, l'archive dispose d'un \gls{checksum} valide, alors les d√©pendances sont valides. C'est du temps processeur\footnote{un seul \gls{checksum} au lieu de 1 par d√©pendance} et de la bande passante\footnote{on ne t√©l√©charge les d√©pendances qu'√† la construction de l'archive et non √† chaque d√©ploiement} qui sont √©conomis√©es et c'est une confiance suppl√©mentaire dans le livrable.

On va ensuite pouvoir d√©poser ce livrable unique\footnote{Comme indiqu√© dans la sous-partie \frquote{\nameref{gestion-de-version}} page \pageref{gestion-de-version}} sur un espace de stockage en attendant son d√©ploiement, par exemple sur un \gls{artifactory} et utiliser une notion de \textit{promotion} pour d√©terminer l'√©tat de ce livrable. Ce syst√®me de promotion permet de d√©terminer si le livrable a √©t√© d√©ploy√© sur un environnement ou non. Dans le cas des projets de la \naq, il y a 3 niveaux de promotions, comme on peut le constater sur l'annexe \ref{annexe:release-naq} : le niveau \frquote{staging}, qui correspond √† un environnement de test interne, celui de \frquote{recette client} et enfin celui de \frquote{production}, qui est identique pour la pr√©-production et la production.

La livraison continue ne permet ainsi pas de d√©ploiement automatique de l'application, mais il est possible de d√©clencher manuellement le d√©ploiement, qui va alors r√©cup√©rer le livrable construit pr√©c√©demment et proc√©der √† son d√©ploiement. Une fois le d√©ploiement termin√©, le livrable sera alors promu sur l'\gls{artifactory} selon l'environnement sur lequel la livraison a √©t√© effectu√©e.

Pour prendre les projets de la \naq{} en exemple, le d√©ploiement en recette est fait sous forme de livraison continue. Le paquet est pr√™t √† √™tre livr√©, mais requiert une validation manuelle pour pouvoir √™tre d√©ploy√© comme on peut le voir sur l'annexe \ref{annexe:release-naq}. Une fois la validation effectu√©e, les scripts ansible\footnote{\url{https://www.ansible.com/}} permettent d'effectuer le d√©ploiement du paquet sur le serveur de recette. Si jamais une erreur survient lors du d√©ploiement, elle sera notifi√©e √† Jenkins qui va alors effectuer un retour en arri√®re et d√©ployer la derni√®re sauvegarde disponible.

\subsubsection{D√©ploiement continu}

La diff√©rence entre le d√©ploiement continu et l'int√©gration r√©side dans l'automatisation du d√©ploiement. La o√π la livraison continue ne permet pas de d√©ployer de fa√ßon automatique, le d√©ploiement continu va permettre de livrer toute version qui passe tous les crit√®res d√©finis : passage des tests, qualit√© de code\ldots

Cette m√©thode de d√©ploiement, bien qu'avantageuse puisque les diff√©rentes versions se d√©ploient continuellement, peut ne pas √™tre adapt√©e √† toutes les entreprises et tous les besoins. Par exemple, certains clients veulent peut-√™tre attendre, pour des raisons commerciales ou l√©gales, et ne souhaitent donc pas mettre en place ce syst√®me. De plus, pour pouvoir effectuer du d√©ploiement continu, il est n√©cessaire de s'assurer que les tests automatis√©s soient nombreux et valident les diff√©rents cas d'usage de l'application, √©tant donn√© qu'il n'y aura pas d'interaction humaine pour le d√©ploiement en production d'une version.

Un des avantages au d√©ploiement continu est que l'on peut, coupl√© √† du monitoring, g√©rer les mont√©es en charge (les pics de trafic) plus facilement que manuellement puisqu'il suffit alors d'instancier et de provisionner alors un nouvel environnement puis de r√©partir le pic de charge sur les diff√©rents serveurs. Cela demande une mise en place initiale un peu plus complexe mais permet de mieux supporter des pics de trafic.

Le d√©ploiement continu est donc une extension de la livraison continue, avec un syst√®me de promotion automatique sur les diff√©rents environnements. Il est alors essentiel de disposer de m√©triques et d'un monitoring efficace pour √™tre au courant d'√©ventuels probl√®mes, comme cela sera √©voqu√© dans la sous-partie \frquote{\nameref{paragraph:monitoring}} (p. \pageref{paragraph:monitoring})

\subsubsection{Gestion de l'infrastructure}

La gestion de l'infrastructure fait √©galement partie de l'automatisation d'un projet. Elle permet de ne plus avoir √† configurer √† la main ou via des scripts difficile √† maintenir les diff√©rents serveurs qui repr√©sentent l'infrastructure n√©cessaire pour h√©berger l'application.

Il suffit d√©sormais de d√©crire dans fichier texte (\frquote{Dockerfile} pour les \glsplural{conteneur} Docker, des fichiers YML pour les scripts ansible\ldots). On parle alors d'\gls{IaC}. Cela permet de passer d'une configuration manuelle, o√π l'on pouvait oublier un paquet √† installer, un fichier de configuration √† renseigner\ldots{} √Ä une infrastructure versionnable dans un \gls{SCM}, permettant ainsi de suivre les √©volutions de cette derni√®re. Il est √©galement plus facile de reproduire l'architecture et donc plus facile de provisionner rapidement de nouveaux serveurs/\glsplural{conteneur}, avec Docker et/ou ansible par exemple.

L'\gls{IaC} peut √©galement s'appliquer sur le serveur d'int√©gration continue, tel que Jenkins, ou l'on va d√©crire les diff√©rentes √©tapes des jobs dans des scripts Groovy\footnote{\url{https://groovy-lang.org/}}, permettant ainsi de d√©crire ce que va effectuer ce job.

\subsubsection{Monitoring}\label{paragraph:monitoring}

Lors de d√©ploiement, de livraison ou d'int√©gration continue, il est n√©cessaire de savoir si les d√©ploiements sont complets et de mani√®re g√©n√©rale, comment r√©pond l'application une fois d√©ploy√©e, afin d'√™tre alert√© en cas d'erreur ou d'incident.

Il est alors important de mettre en place des logs et du monitoring. Cela peut servir √† suivre plusieurs comportements, tel que le taux d'utilisation du processeur par le serveur, son utilisation du disque ou encore sa consommation de m√©moire vive.

Ces logs peuvent √™tre le r√©sultat des t√¢ches effectu√©es par Jenkins, tel qu'on peut le voir sur la figure \ref{fig:jenkins-results}. On distingue alors au premier coup d'≈ìil l'√©tat de l'application et on peut consulter les d√©tails de chaque √©tape afin de savoir ce qui a r√©ussi/√©chou√©.

\newImage{0.45}{jenkins-results.png}{M√©triques sur les r√©sultats des jobs Jenkins}{jenkins-results}

Pour une application web, il est √©galement n√©cessaire de surveiller les codes retours \gls{HTTP} envoy√©s pour distinguer les erreurs des utilisateurs (retours \gls{HTTP} 4xx) des erreurs serveurs (retours \gls{HTTP} 5xx) et √©galement surveiller les requ√™tes \gls{HTTP} valides (retours \gls{HTTP} 2xx). Ce monitoring permet ainsi de d√©tecter les potentielles tentatives d'intrusions (un grand nombre d'erreurs utilisateurs sur un formulaire de connexion peut indiquer une tentative d'acc√®s non autoris√©e) ou encore des erreurs de l'application (une page sp√©cifique qui retourne constamment des erreurs serveurs est une page sur laquelle il est important de se concentrer puisqu'elle contient s√ªrement un bug)

Il est √©galement n√©cessaire de surveiller les logs de l'application en elle-m√™me. Pour cela, \citetitle{12factor} \cite{12factor} recommande d'√©crire les logs de l'application sur deux sorties : \frquote{stdout}, qui correspond √† la sortie standard et \frquote{stderr} qui correspond √† la sortie d'erreur standard. Pourquoi ne pas utiliser des fichiers pour pouvoir √©crire ? Car en d√©veloppement, on souhaite avoir les logs rapidement, en g√©n√©ral dans la console d'ex√©cution et en production, on utilise les outils qui ex√©cutent l'application pour pouvoir capturer les logs et les √©crire aux endroits souhait√©s (dans les logs Docker par exemple, ou dans un fichier de logs Apache). Cela permet donc une plus grande interchangeabilit√© et facilit√© de suivi des logs. 

√âvidemment, il est possible d'√™tre alert√© lors d'une erreur pr√©sente dans les logs, via des canaux vari√©s qui peuvent √™tre des e-mails, un message sur un canal Mattermost\footnote{\url{https://mattermost.com/}}\ldots{}. De plus, des solutions d√©di√©es au suivi d'erreurs existent, tel que Sentry\footnote{Auto-h√©bergeable - \url{https://sentry.io/}} qui va permettre de s'int√©grer dans le code de l'application via des \gls{SDK} dans de nombreux langages. Cela permet d'obtenir en temps r√©el les erreurs non trait√©es qui surviennent dans l'application, avec leur contexte (valeurs des variables d√©clar√©es √† l'instant ou l'erreur est survenue, pile d'erreur\ldots). Sentry va √©galement s'int√©grer avec le \gls{SCM} utilis√© (Gitlab ou \github{} par exemple) et cr√©er des issues\footnote{Ticket de suivi d'erreur} afin de garder une trace des erreurs au fur et √† mesure et de l'impact que cela a eu sur les utilisateurs (si seulement 10 personnes ont eu cette erreur ou bien 5000 par exemple). 

\subsection{Et la s√©curit√© dans tout √ßa ?}

Un projet automatis√© de A √† Z peut √™tre test√© int√©gralement, si la s√©curit√© autour de l'infrastructure d'int√©gration et de d√©ploiement n'est pas s√©curis√©e, cela peut compromettre le projet tout entier.

En effet, si une application vient √† √™tre d√©ploy√©e de fa√ßon automatique, il va falloir que les outils d√©ployant et testant automatiquement l'application aient acc√®s aux donn√©es de cette derni√®re. Ces donn√©es peuvent parfois contenir des tokens, des cl√©s d'\gls{API}\ldots Il faut alors r√©fl√©chir √† la fa√ßon de s√©curiser l'infrastructure. 

Il faut tout d'abord restreindre les acc√®s aux diff√©rents outils d'automatisation. Pour cela, on peut se servir d'un pare feu, qui va filtrer les connexions entrantes sur les diff√©rents serveurs. On peut √©galement mettre en place une \gls{DMZ}, ce qui permet ainsi de s√©parer le r√©seau interne de celui externe, connect√© √† Internet et qui contient les applications ayant besoin d'√™tre accessible via l'ext√©rieur. En plus de cela, on peut √©galement restreindre les acc√®s aux diff√©rentes applications via la mise en place d'un \gls{VPN}, qui permet l'acc√®s aux applications via une connexion s√©curis√©e, comme si l'on √©tait pr√©sent sur site et √©vite ainsi d'avoir √† exposer les applications sur Internet. Toutes ces mesures sont valables pour tout type d'application, automatis√©e ou non. 

Il est √©galement possible de mettre en place un bastion qui permet alors de restreindre les acc√®s \gls{SSH} aux machines pour effectuer des t√¢ches d'administrations. En effet, avec un bastion, on ne peut pas se connecter directement en \gls{SSH} sur les machines h√©bergeant les applications. Il faut passer par une machine d√©di√©e, expos√©e √† Internet (au contraire des autres, qui sont sur un r√©seau priv√©) et dont la s√©curit√© est souvent renforc√©e. Un des avantages est que l'on peut √©teindre le bastion une fois les t√¢ches d'administration effectu√©es et ainsi couper tout acc√®s \gls{SSH} sur les machines.

\newImage{0.30}{bastion.png}{Illustration d'un r√©seau avec un bastion -  \citetitle{bastion} \cite{bastion} \url{https://blog.octo.com/le-bastion-ssh/}}{bastion}

On peut (\emph{et l'on doit}) aussi se r√©f√©rer √† la documentation des outils d'automatisation utilis√©s. Par exemple, la documentation de Jenkins\footnote{\url{https://jenkins.io/doc/}} ainsi que le livre num√©rique \citetitle{jenkins-guide} \cite[chapitre 7, S√©curiser Jenkins]{jenkins-guide} d√©crivent les fa√ßons de s√©curiser l'outil et √©viter ainsi que le serveur d'int√©gration et de d√©ploiement continu ne servent de vecteur d'attaque pour compromettre l'application (\emph{ou pire, l'entreprise enti√®re, √©tant donn√© qu'un syst√®me d'int√©gration continu est souvent utilis√© pour plusieurs projets}). Une des premi√®res mesures est de restreindre les acc√®s utilisateurs, en appliquant le principe de moindre privil√®ge (voir \citetitle{anssi-least-privilege} \cite{anssi-least-privilege}). Cela signifie donner uniquement les droits strictement n√©cessaires. Si un utilisateur a simplement besoin de consulter les rapports, il n'y a pas d'int√©r√™t de lui donner les droits pour pouvoir √©diter la configuration permettant de g√©n√©rer ces derniers.

Concernant les interactions entre le serveur d'int√©gration continue, \gls{SCM} et les diff√©rents serveurs, il peut √™tre n√©cessaire de cr√©er un compte de service (\emph{compte syst√®me, n'√©tant reli√© √† aucun utilisateur et disposant des droits minimaux pour l'ex√©cution de la t√¢che pour lequel il est utilis√©}) avec des acc√®s par cl√© \gls{SSH} utilis√©s pour les d√©ploiements. L'utilisation d'une cl√© \gls{SSH} plut√¥t qu'un mot de passe est obligatoire puisque la demande de mot de passe se fait de fa√ßon interactive (et requiert donc une intervention utilisateur)\footnote{M√™me s'il est possible de contourner ce fonctionnement, par exemple avec sshpass, il est recommand√© d'utiliser des cl√©s \gls{SSH}}. De m√™me, l'acc√®s aux serveurs doit √™tre limit√© et surtout contr√¥l√©. Il faut ainsi pr√©f√©rer des comptes nominatif pour les personnes intervenant manuellement sur le serveur, m√™me si leur cr√©ation peut s'av√©rer plus fastidieuse plut√¥t qu'un seul compte administrateur partag√© entre les membres de l'√©quipe. Ainsi, si un compte vient √™tre compromis, il est plus facile de r√©voquer ses acc√®s plut√¥t que de bloquer l'acc√®s √† tous les membres de l'√©quipe.

Finalement et comme on peut le lire dans \citetitle{jenkins-security} \cite{jenkins-security}, il est important de savoir les limites de l'outil. Il est √©galement important d'en maitriser la distribution des acc√®s, sous peine de se retrouver √† donner des acc√®s privil√©gi√©s √† une personne √† qui l'on pensait simplement donner des droits d'ex√©cution. L'exemple donn√© dans cet article\footnote{L'exemple r√©sum√© est le suivant : contourner le fonctionnement d'une demande d'interaction utilisateur pour pouvoir ex√©cuter des commandes sur le serveur, dans une boucle, ce qui revient alors √† disposer d'un terminal} est totalement valable, puisqu'un d√©veloppeur qui peut renseigner des param√®tres avant (ou durant) l'ex√©cution d'un job peut tout √† fait y inclure des commandes, qui peuvent potentiellement √™tre ex√©cut√©es et amener √† des fuites de secrets, identifiants ou mot de passe\ldots{} 

Concernant les applications web, l'organisation \gls{OWASP}\footnote{\url{https://www.owasp.org}} est reconnue pour ses conseils et bonnes pratiques dans le domaine de la s√©curit√©. Elle fournit des outils afin de tester ses applications lors de leur d√©veloppement (tel que ZAP\footnote{Zed Attack Proxy} qui permet de d√©tecter automatiquement les vuln√©rabilit√©s connues lors du d√©veloppement d'applications web) ou encore des listes de bonnes pratiques tel que par exemple les dix failles de s√©curit√© les plus communes dans un projet et comment s'en pr√©munir\footnote{\url{https://www.owasp.org/index.php/Category:OWASP_Top_Ten_Project}}
